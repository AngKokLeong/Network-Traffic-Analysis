{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Traffic Classification using Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Develop classification models using Python programming to analyze a network-related dataset. \n",
    "\n",
    "The primary goal is to explore the dataset, preprocess it, create and evaluate different classification models, and report your findings. \n",
    "\n",
    "This assignment will enhance your understanding of machine learning techniques, data preprocessing, and model evaluation while applying them to a practical problem related to network security."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a real-world dataset created by collecting network data from Universidad Del Cauca, Popayn, Colombia over six days (April 26, 27, 28 and May 9, 11 and 15) of 2017 using multiple packet capturing tools and data extracting tools. \n",
    "\n",
    "This dataset is consisting of 3,577,296 instances and 87 features and originally designed for application classification. Each row represents a traffic flow from a source to a destination and each column represents features of the traffic data.\n",
    "\n",
    "This dataset is downloaded from Kaggle \"IP Network Traffic Flows, Labeled with 75 Apps.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.rfc-editor.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test attempts to test on the dataset to determine which application does the configuration belongs to based on the prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current dataset from Kaggle is presented similar to a Session data.\n",
    "\n",
    "According to the book \"The Tao of Network Security Monitoring\" by Richard Bejtlich in Chapter 7. Session Data, the chapter describes Session Data as a summary of conversation between two parties.\n",
    "\n",
    "The basic elements of Session Data consists of:\n",
    "- Source IP\n",
    "- Source Port\n",
    "- Destination IP\n",
    "- Destination Port\n",
    "- Timestamp\n",
    "- Measure of the amount of information exchanged during the session\n",
    "\n",
    "The reason why Session Data is used in the analysis is because Session Data ability to track down intruder activities in content-neutral way. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumption Made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Origin of CICFlowMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.unb.ca/cic/research/applications.html#CICFlowMeter\n",
    "\n",
    "https://www.kaggle.com/datasets/jsrojas/ip-network-traffic-flows-labeled-with-87-apps \n",
    "\n",
    "https://www.ntop.org/products/traffic-analysis/ntop/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (24.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: setuptools in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (75.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: kagglehub in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: requests in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from requests->kagglehub) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from seaborn) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from ipywidgets) (8.31.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: colorama in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack_data in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --upgrade setuptools \n",
    "%pip install --upgrade pandas \n",
    "%pip install --upgrade scikit-learn\n",
    "%pip install --upgrade kagglehub \n",
    "\n",
    "%pip install --upgrade matplotlib \n",
    "%pip install --upgrade seaborn \n",
    "%pip install --upgrade ipywidgets \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install PyTorch with CUDA (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section installs the Pytorch with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: filelock in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchvision --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install PyTorch without Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\angko\\desktop\\network-analysis-project\\.conda\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import matplotlib\n",
    "import seaborn\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving data using kagglehub package to simplify the data retrieval process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_csv_file_from_kaggle_to_project_folder():\n",
    "\n",
    "    while True:\n",
    "        path = kagglehub.dataset_download(\"jsrojas/ip-network-traffic-flows-labeled-with-87-apps\")\n",
    "\n",
    "        # Verify if this dataset has been downloaded before\n",
    "        if len(os.listdir(path)) == 0:\n",
    "            \n",
    "            #Verify if the path provided by kagglehub exists\n",
    "            if os.path.isdir(path):\n",
    "                #remove the folder so that new csv file can be downloaded\n",
    "                os.removedirs(path)\n",
    "\n",
    "        else:\n",
    "            csv_file = os.listdir(path)\n",
    "            ## https://www.freecodecamp.org/news/python-get-current-directory/\n",
    "\n",
    "            current_project_folder: str = os.getcwd()\n",
    "            destination_file_path: str = os.path.join(current_project_folder, csv_file[0])            \n",
    "            source_file_path: str = os.path.join(path, csv_file[0])\n",
    "            \n",
    "            shutil.move(source_file_path, destination_file_path)\n",
    "\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/jsrojas/ip-network-traffic-flows-labeled-with-87-apps?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 514M/514M [00:24<00:00, 21.8MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "download_csv_file_from_kaggle_to_project_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Mar_28_02:30:10_Pacific_Daylight_Time_2024\n",
      "Cuda compilation tools, release 12.4, V12.4.131\n",
      "Build cuda_12.4.r12.4/compiler.34097967_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 14 17:08:55 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 561.17                 Driver Version: 561.17         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A500 Laptop GPU   WDDM  |   00000000:03:00.0 Off |                  N/A |\n",
      "| N/A   52C    P8              5W /   30W |      69MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      5552      C   ...-Analysis-Project\\.conda\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_CSV_FILE: str = os.path.join(os.getcwd(), \"Dataset-Unicauca-Version2-87Atts.csv\")\n",
    "PROJECT_FOLDER_FILE_PATH: str = os.path.join(os.getcwd())\n",
    "STACKED_AUTOENCODER_MODEL_FILE_PATH: str = os.path.join(PROJECT_FOLDER_FILE_PATH, \"stacked_autoencoder_best_model.pt\")\n",
    "SUPERVISED_STACKED_AUTOENCODER_MODEL_FILE_PATH: str = os.path.join(PROJECT_FOLDER_FILE_PATH, \"supervised_stacked_autoencoder_best_model.pt\")\n",
    "CLASSIFICATION_TEST_STACKED_AUTOENCODER_MODEL_FILE_PATH: str = os.path.join(PROJECT_FOLDER_FILE_PATH, \"classification_test_stacked_autoencoder_best_model.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading into DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load and explore the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to load the data into pandas dataframe for the data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size: int = 100000\n",
    "data_chunks: list = []\n",
    "\n",
    "for chunk in pandas.read_csv(SOURCE_CSV_FILE, chunksize=chunk_size):\n",
    "    data_chunks.append(chunk)\n",
    "\n",
    "\n",
    "network_traffic_analysis_dataframe: pandas.DataFrame = pandas.concat(data_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow.ID</th>\n",
       "      <th>Source.IP</th>\n",
       "      <th>Source.Port</th>\n",
       "      <th>Destination.IP</th>\n",
       "      <th>Destination.Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow.Duration</th>\n",
       "      <th>Total.Fwd.Packets</th>\n",
       "      <th>Total.Backward.Packets</th>\n",
       "      <th>...</th>\n",
       "      <th>Active.Std</th>\n",
       "      <th>Active.Max</th>\n",
       "      <th>Active.Min</th>\n",
       "      <th>Idle.Mean</th>\n",
       "      <th>Idle.Std</th>\n",
       "      <th>Idle.Max</th>\n",
       "      <th>Idle.Min</th>\n",
       "      <th>Label</th>\n",
       "      <th>L7Protocol</th>\n",
       "      <th>ProtocolName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172.19.1.46-10.200.7.7-52422-3128-6</td>\n",
       "      <td>172.19.1.46</td>\n",
       "      <td>52422</td>\n",
       "      <td>10.200.7.7</td>\n",
       "      <td>3128</td>\n",
       "      <td>6</td>\n",
       "      <td>26/04/201711:11:17</td>\n",
       "      <td>45523</td>\n",
       "      <td>22</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>131</td>\n",
       "      <td>HTTP_PROXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172.19.1.46-10.200.7.7-52422-3128-6</td>\n",
       "      <td>10.200.7.7</td>\n",
       "      <td>3128</td>\n",
       "      <td>172.19.1.46</td>\n",
       "      <td>52422</td>\n",
       "      <td>6</td>\n",
       "      <td>26/04/201711:11:17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>131</td>\n",
       "      <td>HTTP_PROXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.200.7.217-50.31.185.39-38848-80-6</td>\n",
       "      <td>50.31.185.39</td>\n",
       "      <td>80</td>\n",
       "      <td>10.200.7.217</td>\n",
       "      <td>38848</td>\n",
       "      <td>6</td>\n",
       "      <td>26/04/201711:11:17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>7</td>\n",
       "      <td>HTTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.200.7.217-50.31.185.39-38848-80-6</td>\n",
       "      <td>50.31.185.39</td>\n",
       "      <td>80</td>\n",
       "      <td>10.200.7.217</td>\n",
       "      <td>38848</td>\n",
       "      <td>6</td>\n",
       "      <td>26/04/201711:11:17</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>7</td>\n",
       "      <td>HTTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192.168.72.43-10.200.7.7-55961-3128-6</td>\n",
       "      <td>192.168.72.43</td>\n",
       "      <td>55961</td>\n",
       "      <td>10.200.7.7</td>\n",
       "      <td>3128</td>\n",
       "      <td>6</td>\n",
       "      <td>26/04/201711:11:17</td>\n",
       "      <td>78068</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>131</td>\n",
       "      <td>HTTP_PROXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577291</th>\n",
       "      <td>10.200.7.199-98.138.79.73-42135-443-6</td>\n",
       "      <td>98.138.79.73</td>\n",
       "      <td>443</td>\n",
       "      <td>10.200.7.199</td>\n",
       "      <td>42135</td>\n",
       "      <td>6</td>\n",
       "      <td>15/05/201705:43:40</td>\n",
       "      <td>2290821</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>91</td>\n",
       "      <td>SSL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577292</th>\n",
       "      <td>10.200.7.217-98.138.79.73-51546-443-6</td>\n",
       "      <td>98.138.79.73</td>\n",
       "      <td>443</td>\n",
       "      <td>10.200.7.217</td>\n",
       "      <td>51546</td>\n",
       "      <td>6</td>\n",
       "      <td>15/05/201705:46:10</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>91</td>\n",
       "      <td>SSL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577293</th>\n",
       "      <td>10.200.7.218-98.138.79.73-44366-443-6</td>\n",
       "      <td>98.138.79.73</td>\n",
       "      <td>443</td>\n",
       "      <td>10.200.7.218</td>\n",
       "      <td>44366</td>\n",
       "      <td>6</td>\n",
       "      <td>15/05/201705:45:39</td>\n",
       "      <td>2591653</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>91</td>\n",
       "      <td>SSL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577294</th>\n",
       "      <td>10.200.7.195-98.138.79.73-52341-443-6</td>\n",
       "      <td>98.138.79.73</td>\n",
       "      <td>443</td>\n",
       "      <td>10.200.7.195</td>\n",
       "      <td>52341</td>\n",
       "      <td>6</td>\n",
       "      <td>15/05/201705:45:59</td>\n",
       "      <td>2622421</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>91</td>\n",
       "      <td>SSL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577295</th>\n",
       "      <td>10.200.7.196-98.138.79.73-34188-443-6</td>\n",
       "      <td>98.138.79.73</td>\n",
       "      <td>443</td>\n",
       "      <td>10.200.7.196</td>\n",
       "      <td>34188</td>\n",
       "      <td>6</td>\n",
       "      <td>15/05/201705:46:05</td>\n",
       "      <td>2009138</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>91</td>\n",
       "      <td>SSL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3577296 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Flow.ID      Source.IP  Source.Port  \\\n",
       "0          172.19.1.46-10.200.7.7-52422-3128-6    172.19.1.46        52422   \n",
       "1          172.19.1.46-10.200.7.7-52422-3128-6     10.200.7.7         3128   \n",
       "2         10.200.7.217-50.31.185.39-38848-80-6   50.31.185.39           80   \n",
       "3         10.200.7.217-50.31.185.39-38848-80-6   50.31.185.39           80   \n",
       "4        192.168.72.43-10.200.7.7-55961-3128-6  192.168.72.43        55961   \n",
       "...                                        ...            ...          ...   \n",
       "3577291  10.200.7.199-98.138.79.73-42135-443-6   98.138.79.73          443   \n",
       "3577292  10.200.7.217-98.138.79.73-51546-443-6   98.138.79.73          443   \n",
       "3577293  10.200.7.218-98.138.79.73-44366-443-6   98.138.79.73          443   \n",
       "3577294  10.200.7.195-98.138.79.73-52341-443-6   98.138.79.73          443   \n",
       "3577295  10.200.7.196-98.138.79.73-34188-443-6   98.138.79.73          443   \n",
       "\n",
       "        Destination.IP  Destination.Port  Protocol           Timestamp  \\\n",
       "0           10.200.7.7              3128         6  26/04/201711:11:17   \n",
       "1          172.19.1.46             52422         6  26/04/201711:11:17   \n",
       "2         10.200.7.217             38848         6  26/04/201711:11:17   \n",
       "3         10.200.7.217             38848         6  26/04/201711:11:17   \n",
       "4           10.200.7.7              3128         6  26/04/201711:11:17   \n",
       "...                ...               ...       ...                 ...   \n",
       "3577291   10.200.7.199             42135         6  15/05/201705:43:40   \n",
       "3577292   10.200.7.217             51546         6  15/05/201705:46:10   \n",
       "3577293   10.200.7.218             44366         6  15/05/201705:45:39   \n",
       "3577294   10.200.7.195             52341         6  15/05/201705:45:59   \n",
       "3577295   10.200.7.196             34188         6  15/05/201705:46:05   \n",
       "\n",
       "         Flow.Duration  Total.Fwd.Packets  Total.Backward.Packets  ...  \\\n",
       "0                45523                 22                      55  ...   \n",
       "1                    1                  2                       0  ...   \n",
       "2                    1                  3                       0  ...   \n",
       "3                  217                  1                       3  ...   \n",
       "4                78068                  5                       0  ...   \n",
       "...                ...                ...                     ...  ...   \n",
       "3577291        2290821                  5                       4  ...   \n",
       "3577292             24                  5                       0  ...   \n",
       "3577293        2591653                  6                       5  ...   \n",
       "3577294        2622421                  4                       3  ...   \n",
       "3577295        2009138                  3                       2  ...   \n",
       "\n",
       "         Active.Std  Active.Max  Active.Min  Idle.Mean  Idle.Std  Idle.Max  \\\n",
       "0               0.0         0.0         0.0        0.0       0.0       0.0   \n",
       "1               0.0         0.0         0.0        0.0       0.0       0.0   \n",
       "2               0.0         0.0         0.0        0.0       0.0       0.0   \n",
       "3               0.0         0.0         0.0        0.0       0.0       0.0   \n",
       "4               0.0         0.0         0.0        0.0       0.0       0.0   \n",
       "...             ...         ...         ...        ...       ...       ...   \n",
       "3577291         0.0         0.0         0.0        0.0       0.0       0.0   \n",
       "3577292         0.0         0.0         0.0        0.0       0.0       0.0   \n",
       "3577293         0.0         0.0         0.0        0.0       0.0       0.0   \n",
       "3577294         0.0         0.0         0.0        0.0       0.0       0.0   \n",
       "3577295         0.0         0.0         0.0        0.0       0.0       0.0   \n",
       "\n",
       "         Idle.Min   Label  L7Protocol  ProtocolName  \n",
       "0             0.0  BENIGN         131    HTTP_PROXY  \n",
       "1             0.0  BENIGN         131    HTTP_PROXY  \n",
       "2             0.0  BENIGN           7          HTTP  \n",
       "3             0.0  BENIGN           7          HTTP  \n",
       "4             0.0  BENIGN         131    HTTP_PROXY  \n",
       "...           ...     ...         ...           ...  \n",
       "3577291       0.0  BENIGN          91           SSL  \n",
       "3577292       0.0  BENIGN          91           SSL  \n",
       "3577293       0.0  BENIGN          91           SSL  \n",
       "3577294       0.0  BENIGN          91           SSL  \n",
       "3577295       0.0  BENIGN          91           SSL  \n",
       "\n",
       "[3577296 rows x 87 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BENIGN'], dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[\"Label\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Handle missing data and outliers.\n",
    "* Perform data visualization to gain insights into the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature and its description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Flow duration\t\t\n",
    "    - Duration of the flow in Microsecond\n",
    "- total Fwd Packet\t\t\n",
    "    - Total packets in the forward direction\n",
    "- total Bwd packets\t\t\n",
    "    - Total packets in the backward direction\n",
    "- total Length of Fwd Packet\t\n",
    "    - Total size of packet in forward direction\n",
    "- total Length of Bwd Packet\t\n",
    "    - Total size of packet in backward direction\n",
    "- Fwd Packet Length Min \t\t\n",
    "    - Minimum size of packet in forward direction\n",
    "- Fwd Packet Length Max \t\t\n",
    "    - Maximum size of packet in forward direction\n",
    "- Fwd Packet Length Mean\t\t\n",
    "    - Mean size of packet in forward direction\n",
    "- Fwd Packet Length Std\t\t\n",
    "    - Standard deviation size of packet in forward direction\n",
    "- Bwd Packet Length Min\t\t\n",
    "    - Minimum size of packet in backward direction\n",
    "- Bwd Packet Length Max\t\t\n",
    "    - Maximum size of packet in backward direction\n",
    "- Bwd Packet Length Mean\t\t\n",
    "    - Mean size of packet in backward direction\n",
    "- Bwd Packet Length Std\t\t\n",
    "    - Standard deviation size of packet in backward direction\n",
    "- Flow Byte/s\t\t\t\n",
    "    - Number of flow packets per second\n",
    "- Flow Packets/s\t\t\t\n",
    "    - Number of flow bytes per second \n",
    "- Flow IAT Mean\t\t\t\n",
    "    - Mean time between two packets sent in the flow\n",
    "- Flow IAT Std\t\t\t\n",
    "    - Standard deviation time between two packets sent in the flow\n",
    "- Flow IAT Max\t\t\t\n",
    "    - Maximum time between two packets sent in the flow\n",
    "- Flow IAT Min\t\t\t\n",
    "    - Minimum time between two packets sent in the flow\n",
    "- Fwd IAT Min\t\t\t\n",
    "    - Minimum time between two packets sent in the forward direction\n",
    "- Fwd IAT Max\t\t\t\n",
    "    - Maximum time between two packets sent in the forward direction\n",
    "- Fwd IAT Mean\t\t\t\n",
    "    - Mean time between two packets sent in the forward direction\n",
    "- Fwd IAT Std\t\t\t\n",
    "    - Standard deviation time between two packets sent in the forward direction\n",
    "- Fwd IAT Total   \t\t\n",
    "    - Total time between two packets sent in the forward direction\n",
    "- Bwd IAT Min\t\t\t\n",
    "    - Minimum time between two packets sent in the backward direction\n",
    "- Bwd IAT Max\t\t\t\n",
    "    - Maximum time between two packets sent in the backward direction\n",
    "- Bwd IAT Mean\t\t\t\n",
    "    - Mean time between two packets sent in the backward direction\n",
    "- Bwd IAT Std\t\t\t\n",
    "    - Standard deviation time between two packets sent in the backward direction\n",
    "- Bwd IAT Total\t\t\t\n",
    "    - Total time between two packets sent in the backward direction\n",
    "- Fwd PSH flag\t\t\t\n",
    "    - Number of times the PSH flag was set in packets travelling in the forward direction (0 for UDP)\n",
    "- Bwd PSH Flag\t\t\t\n",
    "    - Number of times the PSH flag was set in packets travelling in the backward direction (0 for UDP)\n",
    "- Fwd URG Flag\t\t\t\n",
    "    - Number of times the URG flag was set in packets travelling in the forward direction (0 for UDP)\n",
    "- Bwd URG Flag\t\t\t\n",
    "    - Number of times the URG flag was set in packets travelling in the backward direction (0 for UDP)\n",
    "- Fwd Header Length\t\t\n",
    "    - Total bytes used for headers in the forward direction\n",
    "- Bwd Header Length\t\t\n",
    "    - Total bytes used for headers in the backward direction\n",
    "- FWD Packets/s\t\t\t\n",
    "    - Number of forward packets per second\n",
    "- Bwd Packets/s\t\t\t\n",
    "    - Number of backward packets per second\n",
    "- Min Packet Length \t\t\n",
    "    - Minimum length of a packet\n",
    "- Max Packet Length \t\t\n",
    "    - Maximum length of a packet\n",
    "- Packet Length Mean \t\t\n",
    "    - Mean length of a packet\n",
    "- Packet Length Std\t\t\n",
    "    - Standard deviation length of a packet\n",
    "- Packet Length Variance  \t\n",
    "    - Variance length of a packet\n",
    "- FIN Flag Count \t\t\t\n",
    "    - Number of packets with FIN\n",
    "- SYN Flag Count \t\t\t\n",
    "    - Number of packets with SYN\n",
    "- RST Flag Count \t\t\t\n",
    "    - Number of packets with RST\n",
    "- PSH Flag Count \t\t\t\n",
    "    - Number of packets with PUSH\n",
    "- ACK Flag Count \t\t\t\n",
    "    - Number of packets with ACK\n",
    "- URG Flag Count \t\t\t\n",
    "    - Number of packets with URG\n",
    "- CWR Flag Count \t\t\t\n",
    "    - Number of packets with CWE\n",
    "- ECE Flag Count \t\t\t\n",
    "    - Number of packets with ECE\n",
    "- down/Up Ratio\t\t\t\n",
    "    - Download and upload ratio\n",
    "- Average Packet Size \t\t\n",
    "    - Average size of packet\n",
    "- Avg Fwd Segment Size \t\t\n",
    "    - Average size observed in the forward direction\n",
    "- AVG Bwd Segment Size \t\t\n",
    "    - Average number of bytes bulk rate in the backward direction\n",
    "- Fwd Header Length\t\t\n",
    "    - Length of the forward packet header\n",
    "- Fwd Avg Bytes/Bulk\t\t\n",
    "    - Average number of bytes bulk rate in the forward direction\n",
    "- Fwd AVG Packet/Bulk \t\t\n",
    "    - Average number of packets bulk rate in the forward direction\n",
    "- Fwd AVG Bulk Rate \t\t\n",
    "    - Average number of bulk rate in the forward direction\n",
    "- Bwd Avg Bytes/Bulk\t\t\n",
    "    - Average number of bytes bulk rate in the backward direction\n",
    "- Bwd AVG Packet/Bulk \t\t\n",
    "    - Average number of packets bulk rate in the backward direction\n",
    "- Bwd AVG Bulk Rate \t\t\n",
    "    - Average number of bulk rate in the backward direction\n",
    "- Subflow Fwd Packets\t\t\n",
    "    - The average number of packets in a sub flow in the forward direction\n",
    "- Subflow Fwd Bytes\t\t\n",
    "    - The average number of bytes in a sub flow in the forward direction\n",
    "- Subflow Bwd Packets\t\t\n",
    "    - The average number of packets in a sub flow in the backward direction\n",
    "- Subflow Bwd Bytes\t\t\n",
    "    - The average number of bytes in a sub flow in the backward direction\n",
    "- Init_Win_bytes_forward\t\t\n",
    "    - The total number of bytes sent in initial window in the forward direction\n",
    "- Init_Win_bytes_backward\t\t\n",
    "    - The total number of bytes sent in initial window in the backward direction\n",
    "- Act_data_pkt_forward\t\t\n",
    "    - Count of packets with at least 1 byte of TCP data payload in the forward direction\n",
    "- min_seg_size_forward\t\t\n",
    "    - Minimum segment size observed in the forward direction\n",
    "- Active Min\t\t\t\n",
    "    - Minimum time a flow was active before becoming idle\n",
    "- Active Mean\t\t\t\n",
    "    - Mean time a flow was active before becoming idle\n",
    "- Active Max\t\t\t\n",
    "    - Maximum time a flow was active before becoming idle\n",
    "- Active Std\t\t\t\n",
    "    - Standard deviation time a flow was active before becoming idle\n",
    "- Idle Min\t\t\t\n",
    "    - Minimum time a flow was idle before becoming active\n",
    "- Idle Mean\t\t\t\n",
    "    - Mean time a flow was idle before becoming active\n",
    "- Idle Max\t\t\t\n",
    "    - Maximum time a flow was idle before becoming active\n",
    "- Idle Std\t\t\t\n",
    "    - Standard deviation time a flow was idle before becoming active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Flow.ID', 'Source.IP', 'Source.Port', 'Destination.IP',\n",
       "       'Destination.Port', 'Protocol', 'Timestamp', 'Flow.Duration',\n",
       "       'Total.Fwd.Packets', 'Total.Backward.Packets',\n",
       "       'Total.Length.of.Fwd.Packets', 'Total.Length.of.Bwd.Packets',\n",
       "       'Fwd.Packet.Length.Max', 'Fwd.Packet.Length.Min',\n",
       "       'Fwd.Packet.Length.Mean', 'Fwd.Packet.Length.Std',\n",
       "       'Bwd.Packet.Length.Max', 'Bwd.Packet.Length.Min',\n",
       "       'Bwd.Packet.Length.Mean', 'Bwd.Packet.Length.Std', 'Flow.Bytes.s',\n",
       "       'Flow.Packets.s', 'Flow.IAT.Mean', 'Flow.IAT.Std', 'Flow.IAT.Max',\n",
       "       'Flow.IAT.Min', 'Fwd.IAT.Total', 'Fwd.IAT.Mean', 'Fwd.IAT.Std',\n",
       "       'Fwd.IAT.Max', 'Fwd.IAT.Min', 'Bwd.IAT.Total', 'Bwd.IAT.Mean',\n",
       "       'Bwd.IAT.Std', 'Bwd.IAT.Max', 'Bwd.IAT.Min', 'Fwd.PSH.Flags',\n",
       "       'Bwd.PSH.Flags', 'Fwd.URG.Flags', 'Bwd.URG.Flags', 'Fwd.Header.Length',\n",
       "       'Bwd.Header.Length', 'Fwd.Packets.s', 'Bwd.Packets.s',\n",
       "       'Min.Packet.Length', 'Max.Packet.Length', 'Packet.Length.Mean',\n",
       "       'Packet.Length.Std', 'Packet.Length.Variance', 'FIN.Flag.Count',\n",
       "       'SYN.Flag.Count', 'RST.Flag.Count', 'PSH.Flag.Count', 'ACK.Flag.Count',\n",
       "       'URG.Flag.Count', 'CWE.Flag.Count', 'ECE.Flag.Count', 'Down.Up.Ratio',\n",
       "       'Average.Packet.Size', 'Avg.Fwd.Segment.Size', 'Avg.Bwd.Segment.Size',\n",
       "       'Fwd.Header.Length.1', 'Fwd.Avg.Bytes.Bulk', 'Fwd.Avg.Packets.Bulk',\n",
       "       'Fwd.Avg.Bulk.Rate', 'Bwd.Avg.Bytes.Bulk', 'Bwd.Avg.Packets.Bulk',\n",
       "       'Bwd.Avg.Bulk.Rate', 'Subflow.Fwd.Packets', 'Subflow.Fwd.Bytes',\n",
       "       'Subflow.Bwd.Packets', 'Subflow.Bwd.Bytes', 'Init_Win_bytes_forward',\n",
       "       'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
       "       'Active.Mean', 'Active.Std', 'Active.Max', 'Active.Min', 'Idle.Mean',\n",
       "       'Idle.Std', 'Idle.Max', 'Idle.Min', 'Label', 'L7Protocol',\n",
       "       'ProtocolName'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type for all columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow.ID                         object\n",
      "Source.IP                       object\n",
      "Source.Port                      int64\n",
      "Destination.IP                  object\n",
      "Destination.Port                 int64\n",
      "Protocol                         int64\n",
      "Timestamp                       object\n",
      "Flow.Duration                    int64\n",
      "Total.Fwd.Packets                int64\n",
      "Total.Backward.Packets           int64\n",
      "Total.Length.of.Fwd.Packets      int64\n",
      "Total.Length.of.Bwd.Packets    float64\n",
      "Fwd.Packet.Length.Max            int64\n",
      "Fwd.Packet.Length.Min            int64\n",
      "Fwd.Packet.Length.Mean         float64\n",
      "Fwd.Packet.Length.Std          float64\n",
      "Bwd.Packet.Length.Max            int64\n",
      "Bwd.Packet.Length.Min            int64\n",
      "Bwd.Packet.Length.Mean         float64\n",
      "Bwd.Packet.Length.Std          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(network_traffic_analysis_dataframe.dtypes[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow.Packets.s    float64\n",
      "Flow.IAT.Mean     float64\n",
      "Flow.IAT.Std      float64\n",
      "Flow.IAT.Max      float64\n",
      "Flow.IAT.Min        int64\n",
      "Fwd.IAT.Total     float64\n",
      "Fwd.IAT.Mean      float64\n",
      "Fwd.IAT.Std       float64\n",
      "Fwd.IAT.Max       float64\n",
      "Fwd.IAT.Min       float64\n",
      "Bwd.IAT.Total     float64\n",
      "Bwd.IAT.Mean      float64\n",
      "Bwd.IAT.Std       float64\n",
      "Bwd.IAT.Max       float64\n",
      "Bwd.IAT.Min       float64\n",
      "Fwd.PSH.Flags       int64\n",
      "Bwd.PSH.Flags       int64\n",
      "Fwd.URG.Flags       int64\n",
      "Bwd.URG.Flags       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(network_traffic_analysis_dataframe.dtypes[21:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bwd.Header.Length           int64\n",
      "Fwd.Packets.s             float64\n",
      "Bwd.Packets.s             float64\n",
      "Min.Packet.Length           int64\n",
      "Max.Packet.Length           int64\n",
      "Packet.Length.Mean        float64\n",
      "Packet.Length.Std         float64\n",
      "Packet.Length.Variance    float64\n",
      "FIN.Flag.Count              int64\n",
      "SYN.Flag.Count              int64\n",
      "RST.Flag.Count              int64\n",
      "PSH.Flag.Count              int64\n",
      "ACK.Flag.Count              int64\n",
      "URG.Flag.Count              int64\n",
      "CWE.Flag.Count              int64\n",
      "ECE.Flag.Count              int64\n",
      "Down.Up.Ratio               int64\n",
      "Average.Packet.Size       float64\n",
      "Avg.Fwd.Segment.Size      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(network_traffic_analysis_dataframe.dtypes[41:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subflow.Bwd.Bytes            int64\n",
      "Init_Win_bytes_forward       int64\n",
      "Init_Win_bytes_backward      int64\n",
      "act_data_pkt_fwd             int64\n",
      "min_seg_size_forward         int64\n",
      "Active.Mean                float64\n",
      "Active.Std                 float64\n",
      "Active.Max                 float64\n",
      "Active.Min                 float64\n",
      "Idle.Mean                  float64\n",
      "Idle.Std                   float64\n",
      "Idle.Max                   float64\n",
      "Idle.Min                   float64\n",
      "Label                       object\n",
      "L7Protocol                   int64\n",
      "ProtocolName                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(network_traffic_analysis_dataframe.dtypes[71:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3577296 entries, 0 to 3577295\n",
      "Data columns (total 87 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   Flow.ID                      object \n",
      " 1   Source.IP                    object \n",
      " 2   Source.Port                  int64  \n",
      " 3   Destination.IP               object \n",
      " 4   Destination.Port             int64  \n",
      " 5   Protocol                     int64  \n",
      " 6   Timestamp                    object \n",
      " 7   Flow.Duration                int64  \n",
      " 8   Total.Fwd.Packets            int64  \n",
      " 9   Total.Backward.Packets       int64  \n",
      " 10  Total.Length.of.Fwd.Packets  int64  \n",
      " 11  Total.Length.of.Bwd.Packets  float64\n",
      " 12  Fwd.Packet.Length.Max        int64  \n",
      " 13  Fwd.Packet.Length.Min        int64  \n",
      " 14  Fwd.Packet.Length.Mean       float64\n",
      " 15  Fwd.Packet.Length.Std        float64\n",
      " 16  Bwd.Packet.Length.Max        int64  \n",
      " 17  Bwd.Packet.Length.Min        int64  \n",
      " 18  Bwd.Packet.Length.Mean       float64\n",
      " 19  Bwd.Packet.Length.Std        float64\n",
      " 20  Flow.Bytes.s                 float64\n",
      " 21  Flow.Packets.s               float64\n",
      " 22  Flow.IAT.Mean                float64\n",
      " 23  Flow.IAT.Std                 float64\n",
      " 24  Flow.IAT.Max                 float64\n",
      " 25  Flow.IAT.Min                 int64  \n",
      " 26  Fwd.IAT.Total                float64\n",
      " 27  Fwd.IAT.Mean                 float64\n",
      " 28  Fwd.IAT.Std                  float64\n",
      " 29  Fwd.IAT.Max                  float64\n",
      " 30  Fwd.IAT.Min                  float64\n",
      " 31  Bwd.IAT.Total                float64\n",
      " 32  Bwd.IAT.Mean                 float64\n",
      " 33  Bwd.IAT.Std                  float64\n",
      " 34  Bwd.IAT.Max                  float64\n",
      " 35  Bwd.IAT.Min                  float64\n",
      " 36  Fwd.PSH.Flags                int64  \n",
      " 37  Bwd.PSH.Flags                int64  \n",
      " 38  Fwd.URG.Flags                int64  \n",
      " 39  Bwd.URG.Flags                int64  \n",
      " 40  Fwd.Header.Length            int64  \n",
      " 41  Bwd.Header.Length            int64  \n",
      " 42  Fwd.Packets.s                float64\n",
      " 43  Bwd.Packets.s                float64\n",
      " 44  Min.Packet.Length            int64  \n",
      " 45  Max.Packet.Length            int64  \n",
      " 46  Packet.Length.Mean           float64\n",
      " 47  Packet.Length.Std            float64\n",
      " 48  Packet.Length.Variance       float64\n",
      " 49  FIN.Flag.Count               int64  \n",
      " 50  SYN.Flag.Count               int64  \n",
      " 51  RST.Flag.Count               int64  \n",
      " 52  PSH.Flag.Count               int64  \n",
      " 53  ACK.Flag.Count               int64  \n",
      " 54  URG.Flag.Count               int64  \n",
      " 55  CWE.Flag.Count               int64  \n",
      " 56  ECE.Flag.Count               int64  \n",
      " 57  Down.Up.Ratio                int64  \n",
      " 58  Average.Packet.Size          float64\n",
      " 59  Avg.Fwd.Segment.Size         float64\n",
      " 60  Avg.Bwd.Segment.Size         float64\n",
      " 61  Fwd.Header.Length.1          int64  \n",
      " 62  Fwd.Avg.Bytes.Bulk           int64  \n",
      " 63  Fwd.Avg.Packets.Bulk         int64  \n",
      " 64  Fwd.Avg.Bulk.Rate            int64  \n",
      " 65  Bwd.Avg.Bytes.Bulk           int64  \n",
      " 66  Bwd.Avg.Packets.Bulk         int64  \n",
      " 67  Bwd.Avg.Bulk.Rate            int64  \n",
      " 68  Subflow.Fwd.Packets          int64  \n",
      " 69  Subflow.Fwd.Bytes            int64  \n",
      " 70  Subflow.Bwd.Packets          int64  \n",
      " 71  Subflow.Bwd.Bytes            int64  \n",
      " 72  Init_Win_bytes_forward       int64  \n",
      " 73  Init_Win_bytes_backward      int64  \n",
      " 74  act_data_pkt_fwd             int64  \n",
      " 75  min_seg_size_forward         int64  \n",
      " 76  Active.Mean                  float64\n",
      " 77  Active.Std                   float64\n",
      " 78  Active.Max                   float64\n",
      " 79  Active.Min                   float64\n",
      " 80  Idle.Mean                    float64\n",
      " 81  Idle.Std                     float64\n",
      " 82  Idle.Max                     float64\n",
      " 83  Idle.Min                     float64\n",
      " 84  Label                        object \n",
      " 85  L7Protocol                   int64  \n",
      " 86  ProtocolName                 object \n",
      "dtypes: float64(36), int64(45), object(6)\n",
      "memory usage: 2.3+ GB\n"
     ]
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source.Port</th>\n",
       "      <th>Destination.Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow.Duration</th>\n",
       "      <th>Total.Fwd.Packets</th>\n",
       "      <th>Total.Backward.Packets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.799938e+04</td>\n",
       "      <td>1.204246e+04</td>\n",
       "      <td>6.005508e+00</td>\n",
       "      <td>2.544247e+07</td>\n",
       "      <td>6.237799e+01</td>\n",
       "      <td>6.534083e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.201713e+04</td>\n",
       "      <td>2.044916e+04</td>\n",
       "      <td>3.274574e-01</td>\n",
       "      <td>4.014430e+07</td>\n",
       "      <td>1.094086e+03</td>\n",
       "      <td>1.108092e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.697000e+03</td>\n",
       "      <td>4.430000e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.280000e+02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.937700e+04</td>\n",
       "      <td>3.128000e+03</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>5.847295e+05</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.379900e+04</td>\n",
       "      <td>3.128000e+03</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>4.500153e+07</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.553400e+04</td>\n",
       "      <td>6.553400e+04</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>4.531900e+05</td>\n",
       "      <td>5.421960e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source.Port  Destination.Port      Protocol  Flow.Duration  \\\n",
       "count  3.577296e+06      3.577296e+06  3.577296e+06   3.577296e+06   \n",
       "mean   3.799938e+04      1.204246e+04  6.005508e+00   2.544247e+07   \n",
       "std    2.201713e+04      2.044916e+04  3.274574e-01   4.014430e+07   \n",
       "min    0.000000e+00      0.000000e+00  0.000000e+00   1.000000e+00   \n",
       "25%    3.697000e+03      4.430000e+02  6.000000e+00   6.280000e+02   \n",
       "50%    4.937700e+04      3.128000e+03  6.000000e+00   5.847295e+05   \n",
       "75%    5.379900e+04      3.128000e+03  6.000000e+00   4.500153e+07   \n",
       "max    6.553400e+04      6.553400e+04  1.700000e+01   1.200000e+08   \n",
       "\n",
       "       Total.Fwd.Packets  Total.Backward.Packets  \n",
       "count       3.577296e+06            3.577296e+06  \n",
       "mean        6.237799e+01            6.534083e+01  \n",
       "std         1.094086e+03            1.108092e+03  \n",
       "min         1.000000e+00            0.000000e+00  \n",
       "25%         2.000000e+00            1.000000e+00  \n",
       "50%         6.000000e+00            5.000000e+00  \n",
       "75%         1.500000e+01            1.500000e+01  \n",
       "max         4.531900e+05            5.421960e+05  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.iloc[:,:10].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total.Length.of.Bwd.Packets</th>\n",
       "      <th>Fwd.Packet.Length.Max</th>\n",
       "      <th>Fwd.Packet.Length.Min</th>\n",
       "      <th>Fwd.Packet.Length.Mean</th>\n",
       "      <th>Fwd.Packet.Length.Std</th>\n",
       "      <th>Bwd.Packet.Length.Max</th>\n",
       "      <th>Bwd.Packet.Length.Min</th>\n",
       "      <th>Bwd.Packet.Length.Mean</th>\n",
       "      <th>Bwd.Packet.Length.Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.445742e+04</td>\n",
       "      <td>5.123645e+02</td>\n",
       "      <td>9.340408e+00</td>\n",
       "      <td>1.149212e+02</td>\n",
       "      <td>1.520501e+02</td>\n",
       "      <td>1.103231e+03</td>\n",
       "      <td>1.113491e+01</td>\n",
       "      <td>2.547845e+02</td>\n",
       "      <td>2.898878e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.124319e+06</td>\n",
       "      <td>1.039319e+03</td>\n",
       "      <td>8.299983e+01</td>\n",
       "      <td>2.464707e+02</td>\n",
       "      <td>2.404702e+02</td>\n",
       "      <td>2.352374e+03</td>\n",
       "      <td>1.055422e+02</td>\n",
       "      <td>5.060731e+02</td>\n",
       "      <td>4.853004e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>2.060000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.657143e+01</td>\n",
       "      <td>7.421124e+01</td>\n",
       "      <td>8.100000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.014286e+01</td>\n",
       "      <td>3.242474e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.629000e+03</td>\n",
       "      <td>6.130000e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.225000e+02</td>\n",
       "      <td>2.079035e+02</td>\n",
       "      <td>1.366000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.567500e+02</td>\n",
       "      <td>4.232105e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.345796e+09</td>\n",
       "      <td>3.283200e+04</td>\n",
       "      <td>1.606000e+04</td>\n",
       "      <td>1.606000e+04</td>\n",
       "      <td>6.225487e+03</td>\n",
       "      <td>3.764800e+04</td>\n",
       "      <td>1.303200e+04</td>\n",
       "      <td>1.303200e+04</td>\n",
       "      <td>8.434804e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total.Length.of.Bwd.Packets  Fwd.Packet.Length.Max  \\\n",
       "count                 3.577296e+06           3.577296e+06   \n",
       "mean                  8.445742e+04           5.123645e+02   \n",
       "std                   2.124319e+06           1.039319e+03   \n",
       "min                   0.000000e+00           0.000000e+00   \n",
       "25%                   0.000000e+00           6.000000e+00   \n",
       "50%                   2.080000e+02           2.060000e+02   \n",
       "75%                   3.629000e+03           6.130000e+02   \n",
       "max                   1.345796e+09           3.283200e+04   \n",
       "\n",
       "       Fwd.Packet.Length.Min  Fwd.Packet.Length.Mean  Fwd.Packet.Length.Std  \\\n",
       "count           3.577296e+06            3.577296e+06           3.577296e+06   \n",
       "mean            9.340408e+00            1.149212e+02           1.520501e+02   \n",
       "std             8.299983e+01            2.464707e+02           2.404702e+02   \n",
       "min             0.000000e+00            0.000000e+00           0.000000e+00   \n",
       "25%             0.000000e+00            6.000000e+00           0.000000e+00   \n",
       "50%             0.000000e+00            4.657143e+01           7.421124e+01   \n",
       "75%             6.000000e+00            1.225000e+02           2.079035e+02   \n",
       "max             1.606000e+04            1.606000e+04           6.225487e+03   \n",
       "\n",
       "       Bwd.Packet.Length.Max  Bwd.Packet.Length.Min  Bwd.Packet.Length.Mean  \\\n",
       "count           3.577296e+06           3.577296e+06            3.577296e+06   \n",
       "mean            1.103231e+03           1.113491e+01            2.547845e+02   \n",
       "std             2.352374e+03           1.055422e+02            5.060731e+02   \n",
       "min             0.000000e+00           0.000000e+00            0.000000e+00   \n",
       "25%             0.000000e+00           0.000000e+00            0.000000e+00   \n",
       "50%             8.100000e+01           0.000000e+00            3.014286e+01   \n",
       "75%             1.366000e+03           0.000000e+00            2.567500e+02   \n",
       "max             3.764800e+04           1.303200e+04            1.303200e+04   \n",
       "\n",
       "       Bwd.Packet.Length.Std  \n",
       "count           3.577296e+06  \n",
       "mean            2.898878e+02  \n",
       "std             4.853004e+02  \n",
       "min             0.000000e+00  \n",
       "25%             0.000000e+00  \n",
       "50%             3.242474e+01  \n",
       "75%             4.232105e+02  \n",
       "max             8.434804e+03  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.iloc[:,11:20].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow.Packets.s</th>\n",
       "      <th>Flow.IAT.Mean</th>\n",
       "      <th>Flow.IAT.Std</th>\n",
       "      <th>Flow.IAT.Max</th>\n",
       "      <th>Flow.IAT.Min</th>\n",
       "      <th>Fwd.IAT.Total</th>\n",
       "      <th>Fwd.IAT.Mean</th>\n",
       "      <th>Fwd.IAT.Std</th>\n",
       "      <th>Fwd.IAT.Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.896338e+04</td>\n",
       "      <td>1.422201e+06</td>\n",
       "      <td>3.365395e+06</td>\n",
       "      <td>1.285020e+07</td>\n",
       "      <td>8.870201e+04</td>\n",
       "      <td>2.418796e+07</td>\n",
       "      <td>3.124467e+06</td>\n",
       "      <td>3.649620e+06</td>\n",
       "      <td>1.209624e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.027620e+05</td>\n",
       "      <td>3.550414e+06</td>\n",
       "      <td>6.260959e+06</td>\n",
       "      <td>2.076518e+07</td>\n",
       "      <td>1.605272e+06</td>\n",
       "      <td>3.962563e+07</td>\n",
       "      <td>8.358652e+06</td>\n",
       "      <td>7.390979e+06</td>\n",
       "      <td>2.049180e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.666667e-02</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.128096e+00</td>\n",
       "      <td>4.150000e+02</td>\n",
       "      <td>8.485281e+00</td>\n",
       "      <td>5.700000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.393752e+01</td>\n",
       "      <td>3.320238e+04</td>\n",
       "      <td>6.836444e+04</td>\n",
       "      <td>2.812395e+05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.892645e+05</td>\n",
       "      <td>3.700679e+04</td>\n",
       "      <td>4.717596e+04</td>\n",
       "      <td>2.076290e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.214963e+03</td>\n",
       "      <td>9.366576e+05</td>\n",
       "      <td>3.980748e+06</td>\n",
       "      <td>2.391546e+07</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>4.001161e+07</td>\n",
       "      <td>1.549711e+06</td>\n",
       "      <td>2.932647e+06</td>\n",
       "      <td>1.926976e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000e+06</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>8.485273e+07</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>8.485256e+07</td>\n",
       "      <td>1.200000e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Flow.Packets.s  Flow.IAT.Mean  Flow.IAT.Std  Flow.IAT.Max  \\\n",
       "count    3.577296e+06   3.577296e+06  3.577296e+06  3.577296e+06   \n",
       "mean     8.896338e+04   1.422201e+06  3.365395e+06  1.285020e+07   \n",
       "std      4.027620e+05   3.550414e+06  6.260959e+06  2.076518e+07   \n",
       "min      1.666667e-02   2.000000e-01  0.000000e+00  1.000000e+00   \n",
       "25%      1.128096e+00   4.150000e+02  8.485281e+00  5.700000e+02   \n",
       "50%      3.393752e+01   3.320238e+04  6.836444e+04  2.812395e+05   \n",
       "75%      4.214963e+03   9.366576e+05  3.980748e+06  2.391546e+07   \n",
       "max      6.000000e+06   1.200000e+08  8.485273e+07  1.200000e+08   \n",
       "\n",
       "       Flow.IAT.Min  Fwd.IAT.Total  Fwd.IAT.Mean   Fwd.IAT.Std   Fwd.IAT.Max  \n",
       "count  3.577296e+06   3.577296e+06  3.577296e+06  3.577296e+06  3.577296e+06  \n",
       "mean   8.870201e+04   2.418796e+07  3.124467e+06  3.649620e+06  1.209624e+07  \n",
       "std    1.605272e+06   3.962563e+07  8.358652e+06  7.390979e+06  2.049180e+07  \n",
       "min    0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00   7.000000e+00  5.000000e+00  0.000000e+00  6.000000e+00  \n",
       "50%    1.000000e+00   3.892645e+05  3.700679e+04  4.717596e+04  2.076290e+05  \n",
       "75%    3.300000e+01   4.001161e+07  1.549711e+06  2.932647e+06  1.926976e+07  \n",
       "max    1.200000e+08   1.200000e+08  1.200000e+08  8.485256e+07  1.200000e+08  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.iloc[:,21:30].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bwd.Header.Length</th>\n",
       "      <th>Fwd.Packets.s</th>\n",
       "      <th>Bwd.Packets.s</th>\n",
       "      <th>Min.Packet.Length</th>\n",
       "      <th>Max.Packet.Length</th>\n",
       "      <th>Packet.Length.Mean</th>\n",
       "      <th>Packet.Length.Std</th>\n",
       "      <th>Packet.Length.Variance</th>\n",
       "      <th>FIN.Flag.Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.743621e+03</td>\n",
       "      <td>7.705816e+04</td>\n",
       "      <td>1.190522e+04</td>\n",
       "      <td>3.043745e+00</td>\n",
       "      <td>1.333250e+03</td>\n",
       "      <td>1.988191e+02</td>\n",
       "      <td>3.035190e+02</td>\n",
       "      <td>2.792736e+05</td>\n",
       "      <td>7.037159e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.039190e+04</td>\n",
       "      <td>3.683153e+05</td>\n",
       "      <td>1.080206e+05</td>\n",
       "      <td>4.145472e+01</td>\n",
       "      <td>2.453395e+03</td>\n",
       "      <td>3.327427e+02</td>\n",
       "      <td>4.326083e+02</td>\n",
       "      <td>7.258608e+05</td>\n",
       "      <td>8.359210e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.333337e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.200000e+01</td>\n",
       "      <td>5.417242e-01</td>\n",
       "      <td>1.009873e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.360000e+02</td>\n",
       "      <td>1.563422e+01</td>\n",
       "      <td>2.951696e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.550000e+02</td>\n",
       "      <td>6.283333e+01</td>\n",
       "      <td>1.069828e+02</td>\n",
       "      <td>1.144531e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.200000e+02</td>\n",
       "      <td>2.164502e+03</td>\n",
       "      <td>8.344459e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.460000e+03</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>4.818125e+02</td>\n",
       "      <td>2.321432e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.284440e+07</td>\n",
       "      <td>6.000000e+06</td>\n",
       "      <td>5.000000e+06</td>\n",
       "      <td>7.063000e+03</td>\n",
       "      <td>3.764800e+04</td>\n",
       "      <td>1.070867e+04</td>\n",
       "      <td>9.268781e+03</td>\n",
       "      <td>8.591031e+07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Bwd.Header.Length  Fwd.Packets.s  Bwd.Packets.s  Min.Packet.Length  \\\n",
       "count       3.577296e+06   3.577296e+06   3.577296e+06       3.577296e+06   \n",
       "mean        1.743621e+03   7.705816e+04   1.190522e+04       3.043745e+00   \n",
       "std         3.039190e+04   3.683153e+05   1.080206e+05       4.145472e+01   \n",
       "min         0.000000e+00   8.333337e-03   0.000000e+00       0.000000e+00   \n",
       "25%         3.200000e+01   5.417242e-01   1.009873e-01       0.000000e+00   \n",
       "50%         1.360000e+02   1.563422e+01   2.951696e+00       0.000000e+00   \n",
       "75%         4.200000e+02   2.164502e+03   8.344459e+01       6.000000e+00   \n",
       "max         1.284440e+07   6.000000e+06   5.000000e+06       7.063000e+03   \n",
       "\n",
       "       Max.Packet.Length  Packet.Length.Mean  Packet.Length.Std  \\\n",
       "count       3.577296e+06        3.577296e+06       3.577296e+06   \n",
       "mean        1.333250e+03        1.988191e+02       3.035190e+02   \n",
       "std         2.453395e+03        3.327427e+02       4.326083e+02   \n",
       "min         0.000000e+00        0.000000e+00       0.000000e+00   \n",
       "25%         6.000000e+00        6.000000e+00       0.000000e+00   \n",
       "50%         3.550000e+02        6.283333e+01       1.069828e+02   \n",
       "75%         1.460000e+03        2.500000e+02       4.818125e+02   \n",
       "max         3.764800e+04        1.070867e+04       9.268781e+03   \n",
       "\n",
       "       Packet.Length.Variance  FIN.Flag.Count  \n",
       "count            3.577296e+06    3.577296e+06  \n",
       "mean             2.792736e+05    7.037159e-03  \n",
       "std              7.258608e+05    8.359210e-02  \n",
       "min              0.000000e+00    0.000000e+00  \n",
       "25%              0.000000e+00    0.000000e+00  \n",
       "50%              1.144531e+04    0.000000e+00  \n",
       "75%              2.321432e+05    0.000000e+00  \n",
       "max              8.591031e+07    1.000000e+00  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.iloc[:,41:50].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RST.Flag.Count</th>\n",
       "      <th>PSH.Flag.Count</th>\n",
       "      <th>ACK.Flag.Count</th>\n",
       "      <th>URG.Flag.Count</th>\n",
       "      <th>CWE.Flag.Count</th>\n",
       "      <th>ECE.Flag.Count</th>\n",
       "      <th>Down.Up.Ratio</th>\n",
       "      <th>Average.Packet.Size</th>\n",
       "      <th>Avg.Fwd.Segment.Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3577296.0</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.655865e-04</td>\n",
       "      <td>4.058210e-01</td>\n",
       "      <td>5.995705e-01</td>\n",
       "      <td>2.773847e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.566412e-04</td>\n",
       "      <td>9.085471e-01</td>\n",
       "      <td>2.075630e+02</td>\n",
       "      <td>1.149212e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.579038e-02</td>\n",
       "      <td>4.910503e-01</td>\n",
       "      <td>4.899855e-01</td>\n",
       "      <td>4.477080e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.561660e-02</td>\n",
       "      <td>1.269945e+00</td>\n",
       "      <td>3.432270e+02</td>\n",
       "      <td>2.464707e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.650000e+01</td>\n",
       "      <td>4.657143e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.637184e+02</td>\n",
       "      <td>1.225000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.930000e+02</td>\n",
       "      <td>1.606300e+04</td>\n",
       "      <td>1.606000e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RST.Flag.Count  PSH.Flag.Count  ACK.Flag.Count  URG.Flag.Count  \\\n",
       "count    3.577296e+06    3.577296e+06    3.577296e+06    3.577296e+06   \n",
       "mean     6.655865e-04    4.058210e-01    5.995705e-01    2.773847e-01   \n",
       "std      2.579038e-02    4.910503e-01    4.899855e-01    4.477080e-01   \n",
       "min      0.000000e+00    0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "25%      0.000000e+00    0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "50%      0.000000e+00    0.000000e+00    1.000000e+00    0.000000e+00   \n",
       "75%      0.000000e+00    1.000000e+00    1.000000e+00    1.000000e+00   \n",
       "max      1.000000e+00    1.000000e+00    1.000000e+00    1.000000e+00   \n",
       "\n",
       "       CWE.Flag.Count  ECE.Flag.Count  Down.Up.Ratio  Average.Packet.Size  \\\n",
       "count       3577296.0    3.577296e+06   3.577296e+06         3.577296e+06   \n",
       "mean              0.0    6.566412e-04   9.085471e-01         2.075630e+02   \n",
       "std               0.0    2.561660e-02   1.269945e+00         3.432270e+02   \n",
       "min               0.0    0.000000e+00   0.000000e+00         0.000000e+00   \n",
       "25%               0.0    0.000000e+00   0.000000e+00         9.000000e+00   \n",
       "50%               0.0    0.000000e+00   1.000000e+00         6.650000e+01   \n",
       "75%               0.0    0.000000e+00   1.000000e+00         2.637184e+02   \n",
       "max               0.0    1.000000e+00   2.930000e+02         1.606300e+04   \n",
       "\n",
       "       Avg.Fwd.Segment.Size  \n",
       "count          3.577296e+06  \n",
       "mean           1.149212e+02  \n",
       "std            2.464707e+02  \n",
       "min            0.000000e+00  \n",
       "25%            6.000000e+00  \n",
       "50%            4.657143e+01  \n",
       "75%            1.225000e+02  \n",
       "max            1.606000e+04  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.iloc[:,51:60].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fwd.Header.Length.1</th>\n",
       "      <th>Fwd.Avg.Bytes.Bulk</th>\n",
       "      <th>Fwd.Avg.Packets.Bulk</th>\n",
       "      <th>Fwd.Avg.Bulk.Rate</th>\n",
       "      <th>Bwd.Avg.Bytes.Bulk</th>\n",
       "      <th>Bwd.Avg.Packets.Bulk</th>\n",
       "      <th>Bwd.Avg.Bulk.Rate</th>\n",
       "      <th>Subflow.Fwd.Packets</th>\n",
       "      <th>Subflow.Fwd.Bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3577296.0</td>\n",
       "      <td>3577296.0</td>\n",
       "      <td>3577296.0</td>\n",
       "      <td>3577296.0</td>\n",
       "      <td>3577296.0</td>\n",
       "      <td>3577296.0</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.653339e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.237799e+01</td>\n",
       "      <td>4.683323e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.008890e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.094086e+03</td>\n",
       "      <td>1.816196e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.520000e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>4.430000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>1.769000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.543950e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.531900e+05</td>\n",
       "      <td>6.780236e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fwd.Header.Length.1  Fwd.Avg.Bytes.Bulk  Fwd.Avg.Packets.Bulk  \\\n",
       "count         3.577296e+06           3577296.0             3577296.0   \n",
       "mean          1.653339e+03                 0.0                   0.0   \n",
       "std           3.008890e+04                 0.0                   0.0   \n",
       "min           0.000000e+00                 0.0                   0.0   \n",
       "25%           4.000000e+01                 0.0                   0.0   \n",
       "50%           1.520000e+02                 0.0                   0.0   \n",
       "75%           3.920000e+02                 0.0                   0.0   \n",
       "max           1.543950e+07                 0.0                   0.0   \n",
       "\n",
       "       Fwd.Avg.Bulk.Rate  Bwd.Avg.Bytes.Bulk  Bwd.Avg.Packets.Bulk  \\\n",
       "count          3577296.0           3577296.0             3577296.0   \n",
       "mean                 0.0                 0.0                   0.0   \n",
       "std                  0.0                 0.0                   0.0   \n",
       "min                  0.0                 0.0                   0.0   \n",
       "25%                  0.0                 0.0                   0.0   \n",
       "50%                  0.0                 0.0                   0.0   \n",
       "75%                  0.0                 0.0                   0.0   \n",
       "max                  0.0                 0.0                   0.0   \n",
       "\n",
       "       Bwd.Avg.Bulk.Rate  Subflow.Fwd.Packets  Subflow.Fwd.Bytes  \n",
       "count          3577296.0         3.577296e+06       3.577296e+06  \n",
       "mean                 0.0         6.237799e+01       4.683323e+04  \n",
       "std                  0.0         1.094086e+03       1.816196e+06  \n",
       "min                  0.0         1.000000e+00       0.000000e+00  \n",
       "25%                  0.0         2.000000e+00       1.200000e+01  \n",
       "50%                  0.0         6.000000e+00       4.430000e+02  \n",
       "75%                  0.0         1.500000e+01       1.769000e+03  \n",
       "max                  0.0         4.531900e+05       6.780236e+08  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.iloc[:,61:70].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subflow.Bwd.Bytes</th>\n",
       "      <th>Init_Win_bytes_forward</th>\n",
       "      <th>Init_Win_bytes_backward</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active.Mean</th>\n",
       "      <th>Active.Std</th>\n",
       "      <th>Active.Max</th>\n",
       "      <th>Active.Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.445742e+04</td>\n",
       "      <td>8.984691e+03</td>\n",
       "      <td>2.123489e+03</td>\n",
       "      <td>4.503535e+01</td>\n",
       "      <td>2.569738e+01</td>\n",
       "      <td>2.981990e+05</td>\n",
       "      <td>1.836406e+05</td>\n",
       "      <td>5.229372e+05</td>\n",
       "      <td>1.676336e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.124319e+06</td>\n",
       "      <td>1.410126e+04</td>\n",
       "      <td>7.704789e+03</td>\n",
       "      <td>9.748192e+02</td>\n",
       "      <td>6.025989e+00</td>\n",
       "      <td>2.349390e+06</td>\n",
       "      <td>1.325838e+06</td>\n",
       "      <td>3.266508e+06</td>\n",
       "      <td>2.064219e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.110000e+02</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>5.840000e+03</td>\n",
       "      <td>2.620000e+02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.629000e+03</td>\n",
       "      <td>1.460000e+04</td>\n",
       "      <td>6.600000e+02</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>3.200000e+01</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.700000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.345796e+09</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>3.286940e+05</td>\n",
       "      <td>5.230000e+02</td>\n",
       "      <td>1.146950e+08</td>\n",
       "      <td>7.297136e+07</td>\n",
       "      <td>1.146950e+08</td>\n",
       "      <td>1.146950e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subflow.Bwd.Bytes  Init_Win_bytes_forward  Init_Win_bytes_backward  \\\n",
       "count       3.577296e+06            3.577296e+06             3.577296e+06   \n",
       "mean        8.445742e+04            8.984691e+03             2.123489e+03   \n",
       "std         2.124319e+06            1.410126e+04             7.704789e+03   \n",
       "min         0.000000e+00           -1.000000e+00            -1.000000e+00   \n",
       "25%         0.000000e+00            4.110000e+02             1.800000e+01   \n",
       "50%         2.080000e+02            5.840000e+03             2.620000e+02   \n",
       "75%         3.629000e+03            1.460000e+04             6.600000e+02   \n",
       "max         1.345796e+09            6.553500e+04             6.553500e+04   \n",
       "\n",
       "       act_data_pkt_fwd  min_seg_size_forward   Active.Mean    Active.Std  \\\n",
       "count      3.577296e+06          3.577296e+06  3.577296e+06  3.577296e+06   \n",
       "mean       4.503535e+01          2.569738e+01  2.981990e+05  1.836406e+05   \n",
       "std        9.748192e+02          6.025989e+00  2.349390e+06  1.325838e+06   \n",
       "min        0.000000e+00         -1.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%        0.000000e+00          2.000000e+01  0.000000e+00  0.000000e+00   \n",
       "50%        2.000000e+00          2.000000e+01  0.000000e+00  0.000000e+00   \n",
       "75%        9.000000e+00          3.200000e+01  4.500000e+01  0.000000e+00   \n",
       "max        3.286940e+05          5.230000e+02  1.146950e+08  7.297136e+07   \n",
       "\n",
       "         Active.Max    Active.Min  \n",
       "count  3.577296e+06  3.577296e+06  \n",
       "mean   5.229372e+05  1.676336e+05  \n",
       "std    3.266508e+06  2.064219e+06  \n",
       "min    0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00  \n",
       "50%    0.000000e+00  0.000000e+00  \n",
       "75%    5.700000e+01  2.000000e+00  \n",
       "max    1.146950e+08  1.146950e+08  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.iloc[:,71:80].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Idle.Std</th>\n",
       "      <th>Idle.Max</th>\n",
       "      <th>Idle.Min</th>\n",
       "      <th>L7Protocol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "      <td>3.577296e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.370991e+06</td>\n",
       "      <td>9.743845e+06</td>\n",
       "      <td>7.252097e+06</td>\n",
       "      <td>1.029508e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.814474e+06</td>\n",
       "      <td>1.888557e+07</td>\n",
       "      <td>1.600754e+07</td>\n",
       "      <td>5.129198e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.260000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.034389e+06</td>\n",
       "      <td>5.369712e+06</td>\n",
       "      <td>1.300000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.738746e+07</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>2.220000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Idle.Std      Idle.Max      Idle.Min    L7Protocol\n",
       "count  3.577296e+06  3.577296e+06  3.577296e+06  3.577296e+06\n",
       "mean   1.370991e+06  9.743845e+06  7.252097e+06  1.029508e+02\n",
       "std    4.814474e+06  1.888557e+07  1.600754e+07  5.129198e+01\n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00\n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  9.100000e+01\n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  1.260000e+02\n",
       "75%    0.000000e+00  8.034389e+06  5.369712e+06  1.300000e+02\n",
       "max    7.738746e+07  1.200000e+08  1.200000e+08  2.220000e+02"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.iloc[:,81:].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect for any null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flow.ID                        0\n",
       "Source.IP                      0\n",
       "Source.Port                    0\n",
       "Destination.IP                 0\n",
       "Destination.Port               0\n",
       "Protocol                       0\n",
       "Timestamp                      0\n",
       "Flow.Duration                  0\n",
       "Total.Fwd.Packets              0\n",
       "Total.Backward.Packets         0\n",
       "Total.Length.of.Fwd.Packets    0\n",
       "Total.Length.of.Bwd.Packets    0\n",
       "Fwd.Packet.Length.Max          0\n",
       "Fwd.Packet.Length.Min          0\n",
       "Fwd.Packet.Length.Mean         0\n",
       "Fwd.Packet.Length.Std          0\n",
       "Bwd.Packet.Length.Max          0\n",
       "Bwd.Packet.Length.Min          0\n",
       "Bwd.Packet.Length.Mean         0\n",
       "Bwd.Packet.Length.Std          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.isnull().sum()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flow.Packets.s    0\n",
       "Flow.IAT.Mean     0\n",
       "Flow.IAT.Std      0\n",
       "Flow.IAT.Max      0\n",
       "Flow.IAT.Min      0\n",
       "Fwd.IAT.Total     0\n",
       "Fwd.IAT.Mean      0\n",
       "Fwd.IAT.Std       0\n",
       "Fwd.IAT.Max       0\n",
       "Fwd.IAT.Min       0\n",
       "Bwd.IAT.Total     0\n",
       "Bwd.IAT.Mean      0\n",
       "Bwd.IAT.Std       0\n",
       "Bwd.IAT.Max       0\n",
       "Bwd.IAT.Min       0\n",
       "Fwd.PSH.Flags     0\n",
       "Bwd.PSH.Flags     0\n",
       "Fwd.URG.Flags     0\n",
       "Bwd.URG.Flags     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.isnull().sum()[21:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bwd.Header.Length         0\n",
       "Fwd.Packets.s             0\n",
       "Bwd.Packets.s             0\n",
       "Min.Packet.Length         0\n",
       "Max.Packet.Length         0\n",
       "Packet.Length.Mean        0\n",
       "Packet.Length.Std         0\n",
       "Packet.Length.Variance    0\n",
       "FIN.Flag.Count            0\n",
       "SYN.Flag.Count            0\n",
       "RST.Flag.Count            0\n",
       "PSH.Flag.Count            0\n",
       "ACK.Flag.Count            0\n",
       "URG.Flag.Count            0\n",
       "CWE.Flag.Count            0\n",
       "ECE.Flag.Count            0\n",
       "Down.Up.Ratio             0\n",
       "Average.Packet.Size       0\n",
       "Avg.Fwd.Segment.Size      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.isnull().sum()[41:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fwd.Header.Length.1        0\n",
       "Fwd.Avg.Bytes.Bulk         0\n",
       "Fwd.Avg.Packets.Bulk       0\n",
       "Fwd.Avg.Bulk.Rate          0\n",
       "Bwd.Avg.Bytes.Bulk         0\n",
       "Bwd.Avg.Packets.Bulk       0\n",
       "Bwd.Avg.Bulk.Rate          0\n",
       "Subflow.Fwd.Packets        0\n",
       "Subflow.Fwd.Bytes          0\n",
       "Subflow.Bwd.Packets        0\n",
       "Subflow.Bwd.Bytes          0\n",
       "Init_Win_bytes_forward     0\n",
       "Init_Win_bytes_backward    0\n",
       "act_data_pkt_fwd           0\n",
       "min_seg_size_forward       0\n",
       "Active.Mean                0\n",
       "Active.Std                 0\n",
       "Active.Max                 0\n",
       "Active.Min                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.isnull().sum()[61:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Idle.Std        0\n",
       "Idle.Max        0\n",
       "Idle.Min        0\n",
       "Label           0\n",
       "L7Protocol      0\n",
       "ProtocolName    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.isnull().sum()[81:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect for any na values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flow.ID                        0\n",
       "Source.IP                      0\n",
       "Source.Port                    0\n",
       "Destination.IP                 0\n",
       "Destination.Port               0\n",
       "Protocol                       0\n",
       "Timestamp                      0\n",
       "Flow.Duration                  0\n",
       "Total.Fwd.Packets              0\n",
       "Total.Backward.Packets         0\n",
       "Total.Length.of.Fwd.Packets    0\n",
       "Total.Length.of.Bwd.Packets    0\n",
       "Fwd.Packet.Length.Max          0\n",
       "Fwd.Packet.Length.Min          0\n",
       "Fwd.Packet.Length.Mean         0\n",
       "Fwd.Packet.Length.Std          0\n",
       "Bwd.Packet.Length.Max          0\n",
       "Bwd.Packet.Length.Min          0\n",
       "Bwd.Packet.Length.Mean         0\n",
       "Bwd.Packet.Length.Std          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.isna().sum()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flow.Packets.s    0\n",
       "Flow.IAT.Mean     0\n",
       "Flow.IAT.Std      0\n",
       "Flow.IAT.Max      0\n",
       "Flow.IAT.Min      0\n",
       "Fwd.IAT.Total     0\n",
       "Fwd.IAT.Mean      0\n",
       "Fwd.IAT.Std       0\n",
       "Fwd.IAT.Max       0\n",
       "Fwd.IAT.Min       0\n",
       "Bwd.IAT.Total     0\n",
       "Bwd.IAT.Mean      0\n",
       "Bwd.IAT.Std       0\n",
       "Bwd.IAT.Max       0\n",
       "Bwd.IAT.Min       0\n",
       "Fwd.PSH.Flags     0\n",
       "Bwd.PSH.Flags     0\n",
       "Fwd.URG.Flags     0\n",
       "Bwd.URG.Flags     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.isna().sum()[21:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bwd.Header.Length         0\n",
       "Fwd.Packets.s             0\n",
       "Bwd.Packets.s             0\n",
       "Min.Packet.Length         0\n",
       "Max.Packet.Length         0\n",
       "Packet.Length.Mean        0\n",
       "Packet.Length.Std         0\n",
       "Packet.Length.Variance    0\n",
       "FIN.Flag.Count            0\n",
       "SYN.Flag.Count            0\n",
       "RST.Flag.Count            0\n",
       "PSH.Flag.Count            0\n",
       "ACK.Flag.Count            0\n",
       "URG.Flag.Count            0\n",
       "CWE.Flag.Count            0\n",
       "ECE.Flag.Count            0\n",
       "Down.Up.Ratio             0\n",
       "Average.Packet.Size       0\n",
       "Avg.Fwd.Segment.Size      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.isna().sum()[41:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fwd.Header.Length.1        0\n",
       "Fwd.Avg.Bytes.Bulk         0\n",
       "Fwd.Avg.Packets.Bulk       0\n",
       "Fwd.Avg.Bulk.Rate          0\n",
       "Bwd.Avg.Bytes.Bulk         0\n",
       "Bwd.Avg.Packets.Bulk       0\n",
       "Bwd.Avg.Bulk.Rate          0\n",
       "Subflow.Fwd.Packets        0\n",
       "Subflow.Fwd.Bytes          0\n",
       "Subflow.Bwd.Packets        0\n",
       "Subflow.Bwd.Bytes          0\n",
       "Init_Win_bytes_forward     0\n",
       "Init_Win_bytes_backward    0\n",
       "act_data_pkt_fwd           0\n",
       "min_seg_size_forward       0\n",
       "Active.Mean                0\n",
       "Active.Std                 0\n",
       "Active.Max                 0\n",
       "Active.Min                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.isna().sum()[61:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Idle.Std        0\n",
       "Idle.Max        0\n",
       "Idle.Min        0\n",
       "Label           0\n",
       "L7Protocol      0\n",
       "ProtocolName    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.isna().sum()[81:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the classes in data columns that are object data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Flow.ID', 'Source.IP', 'Destination.IP', 'Timestamp', 'Label',\n",
       "       'ProtocolName'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.select_dtypes(\"object\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the classes in Label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BENIGN'], dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[\"Label\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping of L7Protocol and ProtocolName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary based on\n",
    "\n",
    "protocol_name_list: list[str] = network_traffic_analysis_dataframe[\"ProtocolName\"].unique()\n",
    "\n",
    "number_of_data_to_iterate: int = len(network_traffic_analysis_dataframe[\"ProtocolName\"].unique())\n",
    "\n",
    "protocol_index_to_name_mapping: dict[int, str] = {}\n",
    "protocol_name_to_index_mapping: dict[str, int] = {}\n",
    "\n",
    "for index in range(number_of_data_to_iterate):\n",
    "    data = network_traffic_analysis_dataframe[network_traffic_analysis_dataframe[\"ProtocolName\"] == protocol_name_list[index]].head(1)[[\"L7Protocol\", \"ProtocolName\"]]\n",
    "\n",
    "    protocol_index_to_name_mapping[data[\"L7Protocol\"].values[0]] = data[\"ProtocolName\"].values[0]\n",
    "    protocol_name_to_index_mapping[data[\"ProtocolName\"].values[0]] = data[\"L7Protocol\"].values[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(131): 'HTTP_PROXY',\n",
       " np.int64(7): 'HTTP',\n",
       " np.int64(130): 'HTTP_CONNECT',\n",
       " np.int64(91): 'SSL',\n",
       " np.int64(126): 'GOOGLE',\n",
       " np.int64(124): 'YOUTUBE',\n",
       " np.int64(119): 'FACEBOOK',\n",
       " np.int64(40): 'CONTENT_FLASH',\n",
       " np.int64(121): 'DROPBOX',\n",
       " np.int64(147): 'WINDOWS_UPDATE',\n",
       " np.int64(178): 'AMAZON',\n",
       " np.int64(212): 'MICROSOFT',\n",
       " np.int64(163): 'TOR',\n",
       " np.int64(122): 'GMAIL',\n",
       " np.int64(70): 'YAHOO',\n",
       " np.int64(68): 'MSN',\n",
       " np.int64(64): 'SSL_NO_CERT',\n",
       " np.int64(125): 'SKYPE',\n",
       " np.int64(221): 'MS_ONE_DRIVE',\n",
       " np.int64(114): 'MSSQL',\n",
       " np.int64(120): 'TWITTER',\n",
       " np.int64(143): 'APPLE_ICLOUD',\n",
       " np.int64(220): 'CLOUDFLARE',\n",
       " np.int64(169): 'UBUNTUONE',\n",
       " np.int64(219): 'OFFICE_365',\n",
       " np.int64(176): 'WIKIPEDIA',\n",
       " np.int64(201): 'OPENSIGNAL',\n",
       " np.int64(5): 'DNS',\n",
       " np.int64(60): 'HTTP_DOWNLOAD',\n",
       " np.int64(142): 'WHATSAPP',\n",
       " np.int64(145): 'APPLE_ITUNES',\n",
       " np.int64(175): 'FTP_DATA',\n",
       " np.int64(132): 'CITRIX',\n",
       " np.int64(140): 'APPLE',\n",
       " np.int64(222): 'MQTT',\n",
       " np.int64(211): 'INSTAGRAM',\n",
       " np.int64(179): 'EBAY',\n",
       " np.int64(123): 'GOOGLE_MAPS',\n",
       " np.int64(81): 'IP_ICMP',\n",
       " np.int64(9): 'NTP',\n",
       " np.int64(148): 'TEAMVIEWER',\n",
       " np.int64(156): 'SPOTIFY',\n",
       " np.int64(203): 'EASYTAXI',\n",
       " np.int64(51): 'MAIL_IMAPS',\n",
       " np.int64(195): 'TWITCH',\n",
       " np.int64(133): 'NETFLIX',\n",
       " np.int64(92): 'SSH',\n",
       " np.int64(200): 'SIMET',\n",
       " np.int64(67): 'UNENCRYPED_JABBER',\n",
       " np.int64(135): 'WAZE',\n",
       " np.int64(153): 'UPNP',\n",
       " np.int64(36): 'EDONKEY',\n",
       " np.int64(69): 'OSCAR',\n",
       " np.int64(167): 'ORACLE',\n",
       " np.int64(210): 'DEEZER',\n",
       " np.int64(159): 'OPENVPN',\n",
       " np.int64(170): 'WHOIS_DAS',\n",
       " np.int64(164): 'SKINNY',\n",
       " np.int64(213): 'STARCRAFT',\n",
       " np.int64(11): 'NFS',\n",
       " np.int64(174): 'RTMP',\n",
       " np.int64(162): 'TEAMSPEAK',\n",
       " np.int64(14): 'SNMP',\n",
       " np.int64(202): '99TAXI',\n",
       " np.int64(48): 'QQ',\n",
       " np.int64(185): 'TELEGRAM',\n",
       " np.int64(1): 'FTP_CONTROL',\n",
       " np.int64(150): 'LOTUS_NOTES',\n",
       " np.int64(158): 'H323',\n",
       " np.int64(139): 'CITRIX_ONLINE',\n",
       " np.int64(134): 'LASTFM',\n",
       " np.int64(85): 'IP_OSPF',\n",
       " np.int64(180): 'CNN',\n",
       " np.int64(13): 'BGP',\n",
       " np.int64(146): 'RADIUS',\n",
       " np.int64(172): 'SOCKS',\n",
       " np.int64(37): 'BITTORRENT',\n",
       " np.int64(191): 'TIMMEU'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocol_index_to_name_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping of Protocol and OSI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 17,  0])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping of the number in Protocol column and the OSI model\n",
    "network_traffic_analysis_dataframe[\"Protocol\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/CanadianInstituteForCybersecurity/CICFlowMeter/blob/master/src/main/java/cic/cs/unb/ca/jnetpcap/PacketReader.java\n",
    "\n",
    "From Line 401 to 438\n",
    "\n",
    "The code implementation shows, if the protocol is TCP then the protocol number is set to 6\n",
    "If the protocol is UDP then the protocol is set to 17\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/CanadianInstituteForCybersecurity/CICFlowMeter/blob/master/src/main/java/cic/cs/unb/ca/jnetpcap/FlowFeature.java\n",
    "\n",
    "From Line 188 to 206 also shows the same implemenatation\n",
    "\n",
    "TCP = 6 \n",
    "UDP = 17\n",
    "\n",
    "Others = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/CanadianInstituteForCybersecurity/CICFlowMeter/blob/master/src/main/java/cic/cs/unb/ca/jnetpcap/BasicFlow.java\n",
    "\n",
    "From line 788 to 795\n",
    "\n",
    "There is a mapping for protocol number to protocol str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the mapping of Protocol to Code will be in this mapping.\n",
    "\n",
    "TCP = 6\n",
    "\n",
    "UDP = 17\n",
    "\n",
    "OTHERS = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCP: str = \"TCP\"\n",
    "UDP: str = \"UDP\"\n",
    "OTHERS: str = \"OTHERS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCP_CODE: int = 6\n",
    "UDP_CODE: int = 17\n",
    "OTHER_CODE: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_to_code_mapping: dict = {\n",
    "    TCP: TCP_CODE,\n",
    "    UDP: UDP_CODE,\n",
    "    OTHERS: OTHER_CODE\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split TimeStamp into 2 different columns (Date and Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://regexr.com/\n",
    "network_traffic_analysis_dataframe[\"Date\"] = network_traffic_analysis_dataframe[\"Timestamp\"].str.extract(r\"(\\d{1,2}\\/\\d{1,2}\\/\\d{2,4})\", expand=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_traffic_analysis_dataframe[\"Time\"] = network_traffic_analysis_dataframe[\"Timestamp\"].str.extract(r\"(\\d{1,2}\\:\\d{1,2}\\:\\d{1,2})\", expand=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Preprocess the data for modeling, including feature scaling and encoding categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the distribution of Application used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L7Protocol and ProtocolName are related where L7Protocol is the unique numerical data that represents the ProtocolName and ProtocolName is the name of the application used to access the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProtocolName\n",
       "GOOGLE            959110\n",
       "HTTP              683734\n",
       "HTTP_PROXY        623210\n",
       "SSL               404883\n",
       "HTTP_CONNECT      317526\n",
       "YOUTUBE           170781\n",
       "AMAZON             86875\n",
       "MICROSOFT          54710\n",
       "GMAIL              40260\n",
       "WINDOWS_UPDATE     34471\n",
       "SKYPE              30657\n",
       "FACEBOOK           29033\n",
       "DROPBOX            25102\n",
       "YAHOO              21268\n",
       "TWITTER            18259\n",
       "CLOUDFLARE         14737\n",
       "MSN                14478\n",
       "CONTENT_FLASH       8589\n",
       "APPLE               7615\n",
       "OFFICE_365          5941\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[\"ProtocolName\"].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis on TCP 3-way handshake in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the SYN Flag Count distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SYN.Flag.Count\n",
       "0    2961853\n",
       "1     615443\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[\"SYN.Flag.Count\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 17,  0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[network_traffic_analysis_dataframe[\"SYN.Flag.Count\"] == 0][\"Protocol\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2957532)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[(network_traffic_analysis_dataframe[\"SYN.Flag.Count\"] == 0) & (network_traffic_analysis_dataframe[\"Protocol\"] == 6)][\"Protocol\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4321)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[(network_traffic_analysis_dataframe[\"SYN.Flag.Count\"] == 0) & (network_traffic_analysis_dataframe[\"Protocol\"] != 6)][\"Protocol\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[network_traffic_analysis_dataframe[\"SYN.Flag.Count\"] == 1][\"Protocol\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.imperva.com/learn/ddos/syn-flood/ \n",
    "\n",
    "https://en.wikipedia.org/wiki/SYN_flood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TCP connection is initiated with SYN packet and there are higher frequency of TCP flow without SYN packets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Flow.ID', 'Source.IP', 'Source.Port', 'Destination.IP',\n",
       "       'Destination.Port', 'Protocol', 'Timestamp', 'Flow.Duration',\n",
       "       'Total.Fwd.Packets', 'Total.Backward.Packets',\n",
       "       'Total.Length.of.Fwd.Packets', 'Total.Length.of.Bwd.Packets',\n",
       "       'Fwd.Packet.Length.Max', 'Fwd.Packet.Length.Min',\n",
       "       'Fwd.Packet.Length.Mean', 'Fwd.Packet.Length.Std',\n",
       "       'Bwd.Packet.Length.Max', 'Bwd.Packet.Length.Min',\n",
       "       'Bwd.Packet.Length.Mean', 'Bwd.Packet.Length.Std', 'Flow.Bytes.s',\n",
       "       'Flow.Packets.s', 'Flow.IAT.Mean', 'Flow.IAT.Std', 'Flow.IAT.Max',\n",
       "       'Flow.IAT.Min', 'Fwd.IAT.Total', 'Fwd.IAT.Mean', 'Fwd.IAT.Std',\n",
       "       'Fwd.IAT.Max', 'Fwd.IAT.Min', 'Bwd.IAT.Total', 'Bwd.IAT.Mean',\n",
       "       'Bwd.IAT.Std', 'Bwd.IAT.Max', 'Bwd.IAT.Min', 'Fwd.PSH.Flags',\n",
       "       'Bwd.PSH.Flags', 'Fwd.URG.Flags', 'Bwd.URG.Flags', 'Fwd.Header.Length',\n",
       "       'Bwd.Header.Length', 'Fwd.Packets.s', 'Bwd.Packets.s',\n",
       "       'Min.Packet.Length', 'Max.Packet.Length', 'Packet.Length.Mean',\n",
       "       'Packet.Length.Std', 'Packet.Length.Variance', 'FIN.Flag.Count',\n",
       "       'SYN.Flag.Count', 'RST.Flag.Count', 'PSH.Flag.Count', 'ACK.Flag.Count',\n",
       "       'URG.Flag.Count', 'CWE.Flag.Count', 'ECE.Flag.Count', 'Down.Up.Ratio',\n",
       "       'Average.Packet.Size', 'Avg.Fwd.Segment.Size', 'Avg.Bwd.Segment.Size',\n",
       "       'Fwd.Header.Length.1', 'Fwd.Avg.Bytes.Bulk', 'Fwd.Avg.Packets.Bulk',\n",
       "       'Fwd.Avg.Bulk.Rate', 'Bwd.Avg.Bytes.Bulk', 'Bwd.Avg.Packets.Bulk',\n",
       "       'Bwd.Avg.Bulk.Rate', 'Subflow.Fwd.Packets', 'Subflow.Fwd.Bytes',\n",
       "       'Subflow.Bwd.Packets', 'Subflow.Bwd.Bytes', 'Init_Win_bytes_forward',\n",
       "       'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
       "       'Active.Mean', 'Active.Std', 'Active.Max', 'Active.Min', 'Idle.Mean',\n",
       "       'Idle.Std', 'Idle.Max', 'Idle.Min', 'Label', 'L7Protocol',\n",
       "       'ProtocolName', 'Date', 'Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore RST Flag data distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/TCP_reset_attack \n",
    "\n",
    "https://www.extrahop.com/blog/tcp-resets-rst-prevent-command-and-control-dos-attacks\n",
    "\n",
    "https://www.rfc-editor.org/info/bcp60\n",
    "Inappropriate TCP resets considered harmful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RST.Flag.Count\n",
       "0    3574915\n",
       "1       2381\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[\"RST.Flag.Count\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protocol\n",
       "6    2381\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[network_traffic_analysis_dataframe[\"RST.Flag.Count\"] == 1][\"Protocol\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow.ID</th>\n",
       "      <th>Source.IP</th>\n",
       "      <th>Source.Port</th>\n",
       "      <th>Destination.IP</th>\n",
       "      <th>Destination.Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow.Duration</th>\n",
       "      <th>Total.Fwd.Packets</th>\n",
       "      <th>Total.Backward.Packets</th>\n",
       "      <th>...</th>\n",
       "      <th>Active.Min</th>\n",
       "      <th>Idle.Mean</th>\n",
       "      <th>Idle.Std</th>\n",
       "      <th>Idle.Max</th>\n",
       "      <th>Idle.Min</th>\n",
       "      <th>Label</th>\n",
       "      <th>L7Protocol</th>\n",
       "      <th>ProtocolName</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>192.168.32.3-10.200.7.8-50687-3128-6</td>\n",
       "      <td>192.168.32.3</td>\n",
       "      <td>50687</td>\n",
       "      <td>10.200.7.8</td>\n",
       "      <td>3128</td>\n",
       "      <td>6</td>\n",
       "      <td>26/04/201711:11:28</td>\n",
       "      <td>118867</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>131</td>\n",
       "      <td>HTTP_PROXY</td>\n",
       "      <td>26/04/2017</td>\n",
       "      <td>11:11:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>192.168.32.3-10.200.7.8-50688-3128-6</td>\n",
       "      <td>192.168.32.3</td>\n",
       "      <td>50688</td>\n",
       "      <td>10.200.7.8</td>\n",
       "      <td>3128</td>\n",
       "      <td>6</td>\n",
       "      <td>26/04/201711:11:28</td>\n",
       "      <td>194774</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>131</td>\n",
       "      <td>HTTP_PROXY</td>\n",
       "      <td>26/04/2017</td>\n",
       "      <td>11:11:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>192.168.32.3-10.200.7.8-50699-3128-6</td>\n",
       "      <td>192.168.32.3</td>\n",
       "      <td>50699</td>\n",
       "      <td>10.200.7.8</td>\n",
       "      <td>3128</td>\n",
       "      <td>6</td>\n",
       "      <td>26/04/201711:11:29</td>\n",
       "      <td>445551</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>131</td>\n",
       "      <td>HTTP_PROXY</td>\n",
       "      <td>26/04/2017</td>\n",
       "      <td>11:11:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>192.168.32.3-10.200.7.8-50704-3128-6</td>\n",
       "      <td>192.168.32.3</td>\n",
       "      <td>50704</td>\n",
       "      <td>10.200.7.8</td>\n",
       "      <td>3128</td>\n",
       "      <td>6</td>\n",
       "      <td>26/04/201711:11:31</td>\n",
       "      <td>245917</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>131</td>\n",
       "      <td>HTTP_PROXY</td>\n",
       "      <td>26/04/2017</td>\n",
       "      <td>11:11:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3579</th>\n",
       "      <td>192.168.32.3-10.200.7.8-50703-3128-6</td>\n",
       "      <td>192.168.32.3</td>\n",
       "      <td>50703</td>\n",
       "      <td>10.200.7.8</td>\n",
       "      <td>3128</td>\n",
       "      <td>6</td>\n",
       "      <td>26/04/201711:11:31</td>\n",
       "      <td>3466473</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>130</td>\n",
       "      <td>HTTP_CONNECT</td>\n",
       "      <td>26/04/2017</td>\n",
       "      <td>11:11:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3549053</th>\n",
       "      <td>192.168.32.93-10.200.7.9-51666-3128-6</td>\n",
       "      <td>192.168.32.93</td>\n",
       "      <td>51666</td>\n",
       "      <td>10.200.7.9</td>\n",
       "      <td>3128</td>\n",
       "      <td>6</td>\n",
       "      <td>15/05/201705:21:22</td>\n",
       "      <td>431352</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>140</td>\n",
       "      <td>APPLE</td>\n",
       "      <td>15/05/2017</td>\n",
       "      <td>05:21:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3549054</th>\n",
       "      <td>192.168.32.93-10.200.7.8-51642-3128-6</td>\n",
       "      <td>192.168.32.93</td>\n",
       "      <td>51642</td>\n",
       "      <td>10.200.7.8</td>\n",
       "      <td>3128</td>\n",
       "      <td>6</td>\n",
       "      <td>15/05/201705:19:19</td>\n",
       "      <td>90338973</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.514784e+07</td>\n",
       "      <td>6.746577e+04</td>\n",
       "      <td>45195545.0</td>\n",
       "      <td>45100134.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>126</td>\n",
       "      <td>GOOGLE</td>\n",
       "      <td>15/05/2017</td>\n",
       "      <td>05:19:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3549061</th>\n",
       "      <td>192.168.32.93-10.200.7.8-51645-3128-6</td>\n",
       "      <td>192.168.32.93</td>\n",
       "      <td>51645</td>\n",
       "      <td>10.200.7.8</td>\n",
       "      <td>3128</td>\n",
       "      <td>6</td>\n",
       "      <td>15/05/201705:19:24</td>\n",
       "      <td>90812319</td>\n",
       "      <td>42</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>4.531954e+07</td>\n",
       "      <td>3.367999e+05</td>\n",
       "      <td>45557693.0</td>\n",
       "      <td>45081386.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>126</td>\n",
       "      <td>GOOGLE</td>\n",
       "      <td>15/05/2017</td>\n",
       "      <td>05:19:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3549080</th>\n",
       "      <td>192.168.32.93-10.200.7.8-51665-3128-6</td>\n",
       "      <td>192.168.32.93</td>\n",
       "      <td>51665</td>\n",
       "      <td>10.200.7.8</td>\n",
       "      <td>3128</td>\n",
       "      <td>6</td>\n",
       "      <td>15/05/201705:21:11</td>\n",
       "      <td>315796</td>\n",
       "      <td>42</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>126</td>\n",
       "      <td>GOOGLE</td>\n",
       "      <td>15/05/2017</td>\n",
       "      <td>05:21:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574573</th>\n",
       "      <td>192.168.150.5-10.200.7.7-47915-3128-6</td>\n",
       "      <td>192.168.150.5</td>\n",
       "      <td>47915</td>\n",
       "      <td>10.200.7.7</td>\n",
       "      <td>3128</td>\n",
       "      <td>6</td>\n",
       "      <td>15/05/201705:34:32</td>\n",
       "      <td>43992080</td>\n",
       "      <td>116</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>365261.0</td>\n",
       "      <td>8.419988e+06</td>\n",
       "      <td>3.776933e+06</td>\n",
       "      <td>12701641.0</td>\n",
       "      <td>5560964.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>7</td>\n",
       "      <td>HTTP</td>\n",
       "      <td>15/05/2017</td>\n",
       "      <td>05:34:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2381 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Flow.ID      Source.IP  Source.Port  \\\n",
       "1900      192.168.32.3-10.200.7.8-50687-3128-6   192.168.32.3        50687   \n",
       "1943      192.168.32.3-10.200.7.8-50688-3128-6   192.168.32.3        50688   \n",
       "2356      192.168.32.3-10.200.7.8-50699-3128-6   192.168.32.3        50699   \n",
       "2858      192.168.32.3-10.200.7.8-50704-3128-6   192.168.32.3        50704   \n",
       "3579      192.168.32.3-10.200.7.8-50703-3128-6   192.168.32.3        50703   \n",
       "...                                        ...            ...          ...   \n",
       "3549053  192.168.32.93-10.200.7.9-51666-3128-6  192.168.32.93        51666   \n",
       "3549054  192.168.32.93-10.200.7.8-51642-3128-6  192.168.32.93        51642   \n",
       "3549061  192.168.32.93-10.200.7.8-51645-3128-6  192.168.32.93        51645   \n",
       "3549080  192.168.32.93-10.200.7.8-51665-3128-6  192.168.32.93        51665   \n",
       "3574573  192.168.150.5-10.200.7.7-47915-3128-6  192.168.150.5        47915   \n",
       "\n",
       "        Destination.IP  Destination.Port  Protocol           Timestamp  \\\n",
       "1900        10.200.7.8              3128         6  26/04/201711:11:28   \n",
       "1943        10.200.7.8              3128         6  26/04/201711:11:28   \n",
       "2356        10.200.7.8              3128         6  26/04/201711:11:29   \n",
       "2858        10.200.7.8              3128         6  26/04/201711:11:31   \n",
       "3579        10.200.7.8              3128         6  26/04/201711:11:31   \n",
       "...                ...               ...       ...                 ...   \n",
       "3549053     10.200.7.9              3128         6  15/05/201705:21:22   \n",
       "3549054     10.200.7.8              3128         6  15/05/201705:19:19   \n",
       "3549061     10.200.7.8              3128         6  15/05/201705:19:24   \n",
       "3549080     10.200.7.8              3128         6  15/05/201705:21:11   \n",
       "3574573     10.200.7.7              3128         6  15/05/201705:34:32   \n",
       "\n",
       "         Flow.Duration  Total.Fwd.Packets  Total.Backward.Packets  ...  \\\n",
       "1900            118867                  8                      14  ...   \n",
       "1943            194774                  8                      15  ...   \n",
       "2356            445551                 10                      20  ...   \n",
       "2858            245917                  8                      14  ...   \n",
       "3579           3466473                 16                      33  ...   \n",
       "...                ...                ...                     ...  ...   \n",
       "3549053         431352                 14                      13  ...   \n",
       "3549054       90338973                 29                      30  ...   \n",
       "3549061       90812319                 42                      29  ...   \n",
       "3549080         315796                 42                      26  ...   \n",
       "3574573       43992080                116                     101  ...   \n",
       "\n",
       "         Active.Min     Idle.Mean      Idle.Std    Idle.Max    Idle.Min  \\\n",
       "1900            0.0  0.000000e+00  0.000000e+00         0.0         0.0   \n",
       "1943            0.0  0.000000e+00  0.000000e+00         0.0         0.0   \n",
       "2356            0.0  0.000000e+00  0.000000e+00         0.0         0.0   \n",
       "2858            0.0  0.000000e+00  0.000000e+00         0.0         0.0   \n",
       "3579            0.0  0.000000e+00  0.000000e+00         0.0         0.0   \n",
       "...             ...           ...           ...         ...         ...   \n",
       "3549053         0.0  0.000000e+00  0.000000e+00         0.0         0.0   \n",
       "3549054        80.0  4.514784e+07  6.746577e+04  45195545.0  45100134.0   \n",
       "3549061       175.0  4.531954e+07  3.367999e+05  45557693.0  45081386.0   \n",
       "3549080         0.0  0.000000e+00  0.000000e+00         0.0         0.0   \n",
       "3574573    365261.0  8.419988e+06  3.776933e+06  12701641.0   5560964.0   \n",
       "\n",
       "          Label  L7Protocol  ProtocolName        Date      Time  \n",
       "1900     BENIGN         131    HTTP_PROXY  26/04/2017  11:11:28  \n",
       "1943     BENIGN         131    HTTP_PROXY  26/04/2017  11:11:28  \n",
       "2356     BENIGN         131    HTTP_PROXY  26/04/2017  11:11:29  \n",
       "2858     BENIGN         131    HTTP_PROXY  26/04/2017  11:11:31  \n",
       "3579     BENIGN         130  HTTP_CONNECT  26/04/2017  11:11:31  \n",
       "...         ...         ...           ...         ...       ...  \n",
       "3549053  BENIGN         140         APPLE  15/05/2017  05:21:22  \n",
       "3549054  BENIGN         126        GOOGLE  15/05/2017  05:19:19  \n",
       "3549061  BENIGN         126        GOOGLE  15/05/2017  05:19:24  \n",
       "3549080  BENIGN         126        GOOGLE  15/05/2017  05:21:11  \n",
       "3574573  BENIGN           7          HTTP  15/05/2017  05:34:32  \n",
       "\n",
       "[2381 rows x 89 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[network_traffic_analysis_dataframe[\"RST.Flag.Count\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protocol\n",
       "6     3570594\n",
       "17       2684\n",
       "0        1637\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[network_traffic_analysis_dataframe[\"RST.Flag.Count\"] == 0][\"Protocol\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the FIN Flag Count distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the documentation of the dataset, the FIN flag is set once the TCP connection ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIN.Flag.Count\n",
       "0    3552122\n",
       "1      25174\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[\"FIN.Flag.Count\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 17,  0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[network_traffic_analysis_dataframe[\"FIN.Flag.Count\"] == 0][\"Protocol\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the documentation of the tools that was used to generate this dataset [https://www.unb.ca/cic/research/applications.html#CICFlowMeter], the TCP flow are usually terminated when there is a connection teardown by the FIN packet.\n",
    "\n",
    "The UDP flows are terminated by flow timeout.\n",
    "\n",
    "The high number of absence FIN packet shows weird occurence and the TCP flow are without FIN packet are abnormally high.\n",
    "\n",
    "There is a mapping done in previous section of the notebook where the index 6 = TCP and 17 = UDP and 0 = other protocol.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Flow Timeout value data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ReadMe.txt of the CICflowMeter [https://github.com/CanadianInstituteForCybersecurity/CICFlowMeter/blob/master/ReadMe.txt], the Flow duration column is measured in Microseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.577296e+06\n",
       "mean     2.544247e+07\n",
       "std      4.014430e+07\n",
       "min      1.000000e+00\n",
       "25%      6.280000e+02\n",
       "50%      5.847295e+05\n",
       "75%      4.500153e+07\n",
       "max      1.200000e+08\n",
       "Name: Flow.Duration, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[\"Flow.Duration\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_microseconds_to_seconds(data: int) -> float:\n",
    "    if data == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return data / 1000000.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0.045523\n",
       "1          0.000001\n",
       "2          0.000001\n",
       "3          0.000217\n",
       "4          0.078068\n",
       "             ...   \n",
       "3577291    2.290821\n",
       "3577292    0.000024\n",
       "3577293    2.591653\n",
       "3577294    2.622421\n",
       "3577295    2.009138\n",
       "Name: Flow.Duration, Length: 3577296, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "network_traffic_analysis_dataframe[\"Flow.Duration\"].apply(transform_microseconds_to_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the TCP PSH Packet Flag distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TCP PSH flag is used for real-time application such as voice and video streaming. The delay in data transmission can cause poor user experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PSH.Flag.Count\n",
       "0    2125554\n",
       "1    1451742\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[\"PSH.Flag.Count\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protocol\n",
       "6     2121233\n",
       "17       2684\n",
       "0        1637\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[network_traffic_analysis_dataframe[\"PSH.Flag.Count\"] == 0][\"Protocol\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protocol\n",
       "6    1451742\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[network_traffic_analysis_dataframe[\"PSH.Flag.Count\"] == 1][\"Protocol\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProtocolName\n",
       "GOOGLE            407360\n",
       "HTTP_CONNECT      192516\n",
       "SSL               184339\n",
       "HTTP              173905\n",
       "HTTP_PROXY        167665\n",
       "YOUTUBE            95905\n",
       "AMAZON             52442\n",
       "MICROSOFT          36443\n",
       "WINDOWS_UPDATE     23998\n",
       "GMAIL              15260\n",
       "FACEBOOK           14978\n",
       "SKYPE              14957\n",
       "YAHOO              13503\n",
       "MSN                 9748\n",
       "TWITTER             9572\n",
       "CLOUDFLARE          7600\n",
       "CONTENT_FLASH       7213\n",
       "DROPBOX             5147\n",
       "APPLE               4016\n",
       "OFFICE_365          2514\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[network_traffic_analysis_dataframe[\"PSH.Flag.Count\"] == 1][\"ProtocolName\"].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://orhanergun.net/understanding-tcp-psh-packet-flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the TCP Ack Flag distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACK.Flag.Count\n",
       "1    2144841\n",
       "0    1432455\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[\"ACK.Flag.Count\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protocol\n",
       "6     1428134\n",
       "17       2684\n",
       "0        1637\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[network_traffic_analysis_dataframe[\"ACK.Flag.Count\"] == 0][\"Protocol\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protocol\n",
       "6    2144841\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[network_traffic_analysis_dataframe[\"ACK.Flag.Count\"] == 1][\"Protocol\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the TCP URG flag packet distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blogpost about TCP PSH [https://orhanergun.net/tcp-psh-vs-urg-whats-the-difference], the URG flag in TCP is the Urgent Pointer field is valid in the packet. This URG flag highlights the portion of the data that requires immediate attention to the Receiver.\n",
    "\n",
    "The Receiver will priortise processing the urgent data first before other data.\n",
    "\n",
    "Typical use case of TCP PSH flag will be data containing control signals or error messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URG.Flag.Count\n",
       "0    2585009\n",
       "1     992287\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[\"URG.Flag.Count\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protocol\n",
       "6     2580688\n",
       "17       2684\n",
       "0        1637\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[network_traffic_analysis_dataframe[\"URG.Flag.Count\"] == 0][\"Protocol\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protocol\n",
       "6    992287\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[network_traffic_analysis_dataframe[\"URG.Flag.Count\"] == 1][\"Protocol\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the CWE Flag distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://kb.clavister.com/317180249/explicit-congestion-notification---ecn-ece-cwe-ns-ect-ce \n",
    "\n",
    "https://www.catchpoint.com/blog/ece-cwr-tcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CWE.Flag.Count\n",
       "0    3577296\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[\"CWE.Flag.Count\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring on the ECE flat distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECE.Flag.Count\n",
       "0    3574947\n",
       "1       2349\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[\"ECE.Flag.Count\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ECN (Explicit Congestion Notification) is a mechanism in TCP/IP to allow Routers to signal if the Routers are almost overloaded.\n",
    "\n",
    "ECE (Echo of Congestion Encountered) is the mark where the receiver see the packet understanding that the sender informs the receiver that it almost experience traffic congestion.\n",
    "\n",
    "CWR (Congestion Window Reduced) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Flow.ID', 'Source.IP', 'Source.Port', 'Destination.IP',\n",
       "       'Destination.Port', 'Protocol', 'Timestamp', 'Flow.Duration',\n",
       "       'Total.Fwd.Packets', 'Total.Backward.Packets',\n",
       "       'Total.Length.of.Fwd.Packets', 'Total.Length.of.Bwd.Packets',\n",
       "       'Fwd.Packet.Length.Max', 'Fwd.Packet.Length.Min',\n",
       "       'Fwd.Packet.Length.Mean', 'Fwd.Packet.Length.Std',\n",
       "       'Bwd.Packet.Length.Max', 'Bwd.Packet.Length.Min',\n",
       "       'Bwd.Packet.Length.Mean', 'Bwd.Packet.Length.Std', 'Flow.Bytes.s',\n",
       "       'Flow.Packets.s', 'Flow.IAT.Mean', 'Flow.IAT.Std', 'Flow.IAT.Max',\n",
       "       'Flow.IAT.Min', 'Fwd.IAT.Total', 'Fwd.IAT.Mean', 'Fwd.IAT.Std',\n",
       "       'Fwd.IAT.Max', 'Fwd.IAT.Min', 'Bwd.IAT.Total', 'Bwd.IAT.Mean',\n",
       "       'Bwd.IAT.Std', 'Bwd.IAT.Max', 'Bwd.IAT.Min', 'Fwd.PSH.Flags',\n",
       "       'Bwd.PSH.Flags', 'Fwd.URG.Flags', 'Bwd.URG.Flags', 'Fwd.Header.Length',\n",
       "       'Bwd.Header.Length', 'Fwd.Packets.s', 'Bwd.Packets.s',\n",
       "       'Min.Packet.Length', 'Max.Packet.Length', 'Packet.Length.Mean',\n",
       "       'Packet.Length.Std', 'Packet.Length.Variance', 'FIN.Flag.Count',\n",
       "       'SYN.Flag.Count', 'RST.Flag.Count', 'PSH.Flag.Count', 'ACK.Flag.Count',\n",
       "       'URG.Flag.Count', 'CWE.Flag.Count', 'ECE.Flag.Count', 'Down.Up.Ratio',\n",
       "       'Average.Packet.Size', 'Avg.Fwd.Segment.Size', 'Avg.Bwd.Segment.Size',\n",
       "       'Fwd.Header.Length.1', 'Fwd.Avg.Bytes.Bulk', 'Fwd.Avg.Packets.Bulk',\n",
       "       'Fwd.Avg.Bulk.Rate', 'Bwd.Avg.Bytes.Bulk', 'Bwd.Avg.Packets.Bulk',\n",
       "       'Bwd.Avg.Bulk.Rate', 'Subflow.Fwd.Packets', 'Subflow.Fwd.Bytes',\n",
       "       'Subflow.Bwd.Packets', 'Subflow.Bwd.Bytes', 'Init_Win_bytes_forward',\n",
       "       'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
       "       'Active.Mean', 'Active.Std', 'Active.Max', 'Active.Min', 'Idle.Mean',\n",
       "       'Idle.Std', 'Idle.Max', 'Idle.Min', 'Label', 'L7Protocol',\n",
       "       'ProtocolName', 'Date', 'Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Down Up Ratio distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Down.Up.Ratio\n",
       "0      1573265\n",
       "1      1410146\n",
       "2       305292\n",
       "3       111856\n",
       "4        72685\n",
       "5        61585\n",
       "6        25359\n",
       "7         8727\n",
       "8         3471\n",
       "11        1618\n",
       "9         1599\n",
       "10         797\n",
       "12         419\n",
       "16          94\n",
       "13          93\n",
       "14          78\n",
       "15          66\n",
       "17          28\n",
       "19          21\n",
       "20          17\n",
       "18          13\n",
       "21          12\n",
       "26           6\n",
       "22           6\n",
       "24           5\n",
       "23           5\n",
       "29           4\n",
       "25           4\n",
       "35           3\n",
       "40           2\n",
       "30           2\n",
       "31           2\n",
       "62           1\n",
       "57           1\n",
       "27           1\n",
       "95           1\n",
       "102          1\n",
       "38           1\n",
       "106          1\n",
       "61           1\n",
       "43           1\n",
       "39           1\n",
       "293          1\n",
       "194          1\n",
       "33           1\n",
       "221          1\n",
       "36           1\n",
       "32           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe[\"Down.Up.Ratio\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude the EDA, there are too much variable to reduce the dimension effectively and to determine which condition would likely be classified as Malignant or Benign.\n",
    "\n",
    "Therefore, the use of deep learning through Stacked Denoising Autoencoder could help to learn the key features in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Columns Removal to prepare for deep learning training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a deep copy of the dataframe containing the network traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_traffic_analysis_dataframe_deep_learning: pandas.DataFrame = network_traffic_analysis_dataframe.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_traffic_analysis_dataframe_deep_learning.drop(labels=\"Label\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_traffic_analysis_dataframe_deep_learning.drop(labels=\"Timestamp\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove date and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_traffic_analysis_dataframe_deep_learning.drop(labels=\"Date\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_traffic_analysis_dataframe_deep_learning.drop(labels=\"Time\", axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove ProtocolName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The protocol name is the application type that is related to the data record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_traffic_analysis_dataframe_deep_learning.drop(labels=\"ProtocolName\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Flow.ID column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because this column Flow.ID is an identifier for each row. There is no meaning in the data therefore it should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_traffic_analysis_dataframe_deep_learning.drop(labels=\"Flow.ID\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Source.IP and Destination.IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_traffic_analysis_dataframe_deep_learning.drop(labels=\"Source.IP\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_traffic_analysis_dataframe_deep_learning.drop(labels=\"Destination.IP\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577291</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577292</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577293</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577294</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577295</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3577296 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "\n",
       "[3577296 rows x 0 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_traffic_analysis_dataframe_deep_learning.select_dtypes([\"object\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52422,  3128,    80, ...,  6507, 10192, 10182])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What are the top 20 Source Ports in this dataset?\n",
    "\n",
    "network_traffic_analysis_dataframe_deep_learning[\"Source.Port\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Train, Validation and Test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train Dataset and Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current dataset distribution is at 80% Train_Validation and 20% Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_dataset, test_dataset = train_test_split(network_traffic_analysis_dataframe_deep_learning, train_size = 0.8, test_size = 0.2, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current dataset distribution after train test split\n",
    "\n",
    "- Train dataset: 60% (0.8 * 0.75)\n",
    "- Test dataset: 20% \n",
    "- Validation dataset: 20% (0.8 * 0.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset = train_test_split(train_validation_dataset, train_size=0.75, test_size=0.25, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_features = train_dataset.drop(labels=\"L7Protocol\", axis=1)\n",
    "train_dataset_target = train_dataset[\"L7Protocol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset_features = validation_dataset.drop(labels=\"L7Protocol\", axis=1)\n",
    "validation_dataset_target = validation_dataset[\"L7Protocol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_features = test_dataset.drop(labels=\"L7Protocol\", axis=1)\n",
    "test_dataset_target = test_dataset[\"L7Protocol\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform min-max normalization on all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalization(input_data: float, minimum_value: float, maximum_value: float) -> float:\n",
    "    \n",
    "    # Function output range: [0, 1]\n",
    "\n",
    "    if (maximum_value - minimum_value) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    result_min_max_value = (input_data - minimum_value) / (maximum_value - minimum_value)\n",
    "    \n",
    "    return result_min_max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_min_max_normalization_in_the_dataframe(dataframe: pandas.DataFrame) -> pandas.DataFrame:\n",
    "\n",
    "    transformed_min_max_normalization_data: dict = {}\n",
    "\n",
    "    for data_column in dataframe.columns:\n",
    "\n",
    "        data_column_minimum_value: float = dataframe[data_column].min()\n",
    "        data_column_maximum_value: float = dataframe[data_column].max()\n",
    "\n",
    "        transformed_data_column: pandas.Series = dataframe[data_column].apply(lambda data: min_max_normalization(data, minimum_value=data_column_minimum_value, maximum_value=data_column_maximum_value))\n",
    "\n",
    "        transformed_min_max_normalization_data[data_column] = transformed_data_column\n",
    "\n",
    "    \n",
    "    transformed_dataframe: pandas.DataFrame = pandas.DataFrame(data = transformed_min_max_normalization_data)\n",
    "    \n",
    "    if transformed_dataframe.columns.difference(validation_dataset.columns).empty == True:\n",
    "        return transformed_dataframe\n",
    "    else:\n",
    "        raise Exception(\"There is a mismatch in the new dataframe.\")\n",
    "\n",
    "    return None\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_normalized = apply_min_max_normalization_in_the_dataframe(train_dataset_features)\n",
    "validation_dataset_normalized = apply_min_max_normalization_in_the_dataframe(validation_dataset_features)\n",
    "test_dataset_normalized = apply_min_max_normalization_in_the_dataframe(test_dataset_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source.Port</th>\n",
       "      <th>Destination.Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow.Duration</th>\n",
       "      <th>Total.Fwd.Packets</th>\n",
       "      <th>Total.Backward.Packets</th>\n",
       "      <th>Total.Length.of.Fwd.Packets</th>\n",
       "      <th>Total.Length.of.Bwd.Packets</th>\n",
       "      <th>Fwd.Packet.Length.Max</th>\n",
       "      <th>Fwd.Packet.Length.Min</th>\n",
       "      <th>...</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active.Mean</th>\n",
       "      <th>Active.Std</th>\n",
       "      <th>Active.Max</th>\n",
       "      <th>Active.Min</th>\n",
       "      <th>Idle.Mean</th>\n",
       "      <th>Idle.Std</th>\n",
       "      <th>Idle.Max</th>\n",
       "      <th>Idle.Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2829033</th>\n",
       "      <td>0.807840</td>\n",
       "      <td>0.047731</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.424625e-08</td>\n",
       "      <td>1.368621e-08</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799074</th>\n",
       "      <td>0.047731</td>\n",
       "      <td>0.792886</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.054740</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>9.797594e-06</td>\n",
       "      <td>1.031028e-06</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412808</th>\n",
       "      <td>0.609790</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.165151e-06</td>\n",
       "      <td>2.657405e-07</td>\n",
       "      <td>0.016661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408912</th>\n",
       "      <td>0.755272</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>8.259300e-07</td>\n",
       "      <td>1.573914e-07</td>\n",
       "      <td>0.015747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548715</th>\n",
       "      <td>0.556795</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.078803</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>3.218177e-06</td>\n",
       "      <td>6.466733e-07</td>\n",
       "      <td>0.042550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446753</th>\n",
       "      <td>0.614658</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878231</th>\n",
       "      <td>0.630238</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>2.477790e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106371</th>\n",
       "      <td>0.047731</td>\n",
       "      <td>0.883206</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.867055</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>2.598730e-06</td>\n",
       "      <td>3.615440e-07</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.170951e-03</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>3.353101e-03</td>\n",
       "      <td>4.381446e-04</td>\n",
       "      <td>0.215538</td>\n",
       "      <td>0.023618</td>\n",
       "      <td>0.235963</td>\n",
       "      <td>0.200993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397935</th>\n",
       "      <td>0.047731</td>\n",
       "      <td>0.790811</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.344832</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>4.309290e-05</td>\n",
       "      <td>1.368621e-08</td>\n",
       "      <td>0.088938</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.569379e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.569379e-07</td>\n",
       "      <td>1.569379e-07</td>\n",
       "      <td>0.344762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344762</td>\n",
       "      <td>0.344762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776261</th>\n",
       "      <td>0.905591</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>2.162167e-06</td>\n",
       "      <td>5.885069e-07</td>\n",
       "      <td>0.015747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2146377 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Source.Port  Destination.Port  Protocol  Flow.Duration  \\\n",
       "2829033     0.807840          0.047731  0.352941       0.000004   \n",
       "1799074     0.047731          0.792886  0.352941       0.054740   \n",
       "2412808     0.609790          0.001221  0.352941       0.003180   \n",
       "1408912     0.755272          0.006760  0.352941       0.004185   \n",
       "1548715     0.556795          0.006760  0.352941       0.078803   \n",
       "...              ...               ...       ...            ...   \n",
       "2446753     0.614658          0.006760  0.352941       0.000006   \n",
       "878231      0.630238          0.001221  0.352941       0.000100   \n",
       "106371      0.047731          0.883206  0.352941       0.867055   \n",
       "3397935     0.047731          0.790811  0.352941       0.344832   \n",
       "1776261     0.905591          0.006760  0.352941       0.000886   \n",
       "\n",
       "         Total.Fwd.Packets  Total.Backward.Packets  \\\n",
       "2829033           0.000009                0.000005   \n",
       "1799074           0.000015                0.000020   \n",
       "2412808           0.000011                0.000010   \n",
       "1408912           0.000011                0.000010   \n",
       "1548715           0.000026                0.000025   \n",
       "...                    ...                     ...   \n",
       "2446753           0.000000                0.000005   \n",
       "878231            0.000004                0.000007   \n",
       "106371            0.000088                0.000017   \n",
       "3397935           0.000042                0.000010   \n",
       "1776261           0.000024                0.000020   \n",
       "\n",
       "         Total.Length.of.Fwd.Packets  Total.Length.of.Bwd.Packets  \\\n",
       "2829033                 4.424625e-08                 1.368621e-08   \n",
       "1799074                 9.797594e-06                 1.031028e-06   \n",
       "2412808                 1.165151e-06                 2.657405e-07   \n",
       "1408912                 8.259300e-07                 1.573914e-07   \n",
       "1548715                 3.218177e-06                 6.466733e-07   \n",
       "...                              ...                          ...   \n",
       "2446753                 0.000000e+00                 0.000000e+00   \n",
       "878231                  2.477790e-07                 0.000000e+00   \n",
       "106371                  2.598730e-06                 3.615440e-07   \n",
       "3397935                 4.309290e-05                 1.368621e-08   \n",
       "1776261                 2.162167e-06                 5.885069e-07   \n",
       "\n",
       "         Fwd.Packet.Length.Max  Fwd.Packet.Length.Min  ...  act_data_pkt_fwd  \\\n",
       "2829033               0.000183               0.000691  ...          0.000012   \n",
       "1799074               0.105263               0.000000  ...          0.000021   \n",
       "2412808               0.016661               0.000000  ...          0.000006   \n",
       "1408912               0.015747               0.000000  ...          0.000006   \n",
       "1548715               0.042550               0.000000  ...          0.000015   \n",
       "...                        ...                    ...  ...               ...   \n",
       "2446753               0.000000               0.000000  ...          0.000000   \n",
       "878231                0.005117               0.000000  ...          0.000003   \n",
       "106371                0.001827               0.000691  ...          0.000122   \n",
       "3397935               0.088938               0.000691  ...          0.000058   \n",
       "1776261               0.015747               0.000000  ...          0.000012   \n",
       "\n",
       "         min_seg_size_forward   Active.Mean  Active.Std    Active.Max  \\\n",
       "2829033              0.416667  0.000000e+00    0.000000  0.000000e+00   \n",
       "1799074              0.416667  0.000000e+00    0.000000  0.000000e+00   \n",
       "2412808              0.666667  0.000000e+00    0.000000  0.000000e+00   \n",
       "1408912              0.666667  0.000000e+00    0.000000  0.000000e+00   \n",
       "1548715              0.666667  0.000000e+00    0.000000  0.000000e+00   \n",
       "...                       ...           ...         ...           ...   \n",
       "2446753              0.666667  0.000000e+00    0.000000  0.000000e+00   \n",
       "878231               0.666667  0.000000e+00    0.000000  0.000000e+00   \n",
       "106371               0.416667  1.170951e-03    0.002309  3.353101e-03   \n",
       "3397935              0.416667  1.569379e-07    0.000000  1.569379e-07   \n",
       "1776261              0.666667  0.000000e+00    0.000000  0.000000e+00   \n",
       "\n",
       "           Active.Min  Idle.Mean  Idle.Std  Idle.Max  Idle.Min  \n",
       "2829033  0.000000e+00   0.000000  0.000000  0.000000  0.000000  \n",
       "1799074  0.000000e+00   0.000000  0.000000  0.000000  0.000000  \n",
       "2412808  0.000000e+00   0.000000  0.000000  0.000000  0.000000  \n",
       "1408912  0.000000e+00   0.000000  0.000000  0.000000  0.000000  \n",
       "1548715  0.000000e+00   0.000000  0.000000  0.000000  0.000000  \n",
       "...               ...        ...       ...       ...       ...  \n",
       "2446753  0.000000e+00   0.000000  0.000000  0.000000  0.000000  \n",
       "878231   0.000000e+00   0.000000  0.000000  0.000000  0.000000  \n",
       "106371   4.381446e-04   0.215538  0.023618  0.235963  0.200993  \n",
       "3397935  1.569379e-07   0.344762  0.000000  0.344762  0.344762  \n",
       "1776261  0.000000e+00   0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[2146377 rows x 80 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the label on this dataset using Stacked Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the data exploration, I am still not sure what are the labels I should indicate based on the criteria or conditions in the dataset.\n",
    "\n",
    "I have found this research paper \"Session-Based Network Intrusion Detection Using a Deep Learning Architecture\" by Yang Yu, Jun Long and Zhiping Cai. (https://www.researchgate.net/publication/319660558_Session-Based_Network_Intrusion_Detection_Using_a_Deep_Learning_Architecture)\n",
    "\n",
    "According to this paper, the findings based on the deep learning architecture proposed in the paper. It was able to learn the essential features from raw network packets to determine normal and malicious network traffics and achieve high detection accuracy using the deep learning architecture.\n",
    "\n",
    "In this section, I will use pytorch with GPU to train and infer the features and labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.version\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset and data loader for deep learning model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert datasets into Tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_normalized_tensor: torch.Tensor = torch.tensor(train_dataset_normalized.to_numpy(), dtype=torch.float32)\n",
    "validation_dataset_normalized_tensor: torch.Tensor = torch.tensor(validation_dataset_normalized.to_numpy(), dtype=torch.float32)\n",
    "test_dataset_normalized_tensor: torch.Tensor = torch.tensor(test_dataset_normalized.to_numpy(), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert target dataset into Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_target_tensor: torch.Tensor = torch.tensor(train_dataset_target.to_numpy(), dtype=torch.int64)\n",
    "validation_dataset_target_tensor: torch.Tensor = torch.tensor(validation_dataset_target.to_numpy(), dtype=torch.int64)\n",
    "test_dataset_target_tensor: torch.Tensor = torch.tensor(test_dataset_target.to_numpy(), dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normalized_tensor_dataset: torch.utils.data.TensorDataset = torch.utils.data.TensorDataset(train_dataset_normalized_tensor, train_dataset_target_tensor)\n",
    "validation_normalized_tensor_dataset: torch.utils.data.TensorDataset = torch.utils.data.TensorDataset(validation_dataset_normalized_tensor, validation_dataset_target_tensor)\n",
    "test_normalized_tensor_dataset: torch.utils.data.TensorDataset = torch.utils.data.TensorDataset(test_dataset_normalized_tensor, test_dataset_target_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Dataset size dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes: dict[str, int] = {\n",
    "    \"train\": len(train_normalized_tensor_dataset),\n",
    "    \"test\": len(test_normalized_tensor_dataset),\n",
    "    \"validation\": len(validation_normalized_tensor_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normalized_tensor_dataloader: torch.utils.data.DataLoader = torch.utils.data.DataLoader(dataset=train_normalized_tensor_dataset, batch_size=64, pin_memory=True)\n",
    "validation_normalized_tensor_dataloader: torch.utils.data.DataLoader = torch.utils.data.DataLoader(dataset=validation_normalized_tensor_dataset, batch_size=64, pin_memory=True)\n",
    "test_normalized_tensor_dataloader: torch.utils.data.DataLoader = torch.utils.data.DataLoader(dataset=test_normalized_tensor_dataset, batch_size=64, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DataLoader dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader_dictionary: dict[str, torch.utils.data.DataLoader] = {\n",
    "    \"train\": train_normalized_tensor_dataloader,\n",
    "    \"validation\": validation_normalized_tensor_dataloader,\n",
    "    \"test\": test_normalized_tensor_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference for Stacked Denoising Autoencoder: https://towardsdatascience.com/stacked-autoencoders-f0a4391ae282\n",
    "\n",
    "Reference Research Paper used: Session-Based Network Intrusion Detection Using a Deep Learning Architecture\n",
    "\n",
    "https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of using Stacked Denoising Autoencoder\n",
    "\n",
    "The dataset itself is non-linear and it will difficult for PCA and K-means to determine which features are relevant and important.\n",
    "\n",
    "Therefore the use of Stacked Denoising Autoencoder is implemented on this dataset and this model can be used to determine the target variables for this dataset. (Semi-supervised learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input size of 1 record = 1 x 81\n",
    "\n",
    "81 -> 40 -> 20 -> 9 -> 20 -> 40 -> 81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each record, there will be 1 row of record with 81 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, x_dimension: int, h_dimension_1: int, h_dimension_2: int, h_dimension_3: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # In the documentation for torch.nn.linear, https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
    "        # The output data type is TensorFloat32 if there are no dtype specified\n",
    "\n",
    "        # By specifying dtype=torch.double, the tensor data type will be able to fit into the torch.sigmoid()\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(x_dimension, h_dimension_1), # 80\n",
    "            torch.nn.Linear(h_dimension_1, h_dimension_2), # 40\n",
    "            torch.nn.Linear(h_dimension_2, h_dimension_3), # 20\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(h_dimension_3, h_dimension_2), # 20\n",
    "            torch.nn.Linear(h_dimension_2, h_dimension_1), # 40\n",
    "            torch.nn.Linear(h_dimension_1, x_dimension) #80\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = self.encoder(data)\n",
    "        data = self.decoder(data)\n",
    "\n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedAutoEncoder(torch.nn.Module):\n",
    "\n",
    "    autoencoder_name_list: list = []\n",
    "    autoencoder_dictionary: dict = {}\n",
    "\n",
    "    def __init__(self, first_layer_dimension: int, second_layer_dimension: int, third_layer_dimension: int, latent_space_dimension: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stacked_autoencoder = torch.nn.Sequential(\n",
    "            AutoEncoder(first_layer_dimension, second_layer_dimension, third_layer_dimension, latent_space_dimension),\n",
    "            AutoEncoder(first_layer_dimension, second_layer_dimension, third_layer_dimension, latent_space_dimension),\n",
    "            AutoEncoder(first_layer_dimension, second_layer_dimension, third_layer_dimension, latent_space_dimension),\n",
    "        )\n",
    "        \n",
    "        \n",
    "\n",
    "    def train_model(self, dataset_loader_dictionary: dict[str, torch.utils.data.DataLoader], model, optimizer, scheduler, number_of_epoch: int = 25 ):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        with TemporaryDirectory() as tempdir:\n",
    "            best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            for epoch in range(number_of_epoch):\n",
    "\n",
    "                print(f\"Current Epoch {epoch} / {number_of_epoch - 1}\")\n",
    "                #print(\"-\" * 10)\n",
    "\n",
    "                for phase in ['train']:\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        model.train()\n",
    "\n",
    "                    running_loss: float = 0.0\n",
    "\n",
    "                    for inputs, labels in dataset_loader_dictionary[phase]:\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        with torch.set_grad_enabled(phase == 'train'):\n",
    "                            outputs = model(inputs)\n",
    "\n",
    "                            if phase == 'train':\n",
    "                                optimizer.step()\n",
    "                            \n",
    "                    if phase == 'train':\n",
    "                        scheduler.step()\n",
    "                    \n",
    "                    if phase == 'training':\n",
    "                        torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "                print()\n",
    "\n",
    "            time_elapsed = time.time() - start_time\n",
    "\n",
    "            print(f\"Training complete in {time_elapsed // 60:.0f} minutes {time_elapsed % 60:.0f} seconds\")\n",
    "            \n",
    "            print(\"\")\n",
    "\n",
    "            model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "\n",
    "        return model\n",
    "\n",
    "    \n",
    "    def _prepare_optimizer(self, autoencoder_parameters):\n",
    "        #stackedAutoEncoder.autoencoder_decoder.parameters()\n",
    "        optimizer: torch.optim.Adam = torch.optim.Adam(autoencoder_parameters, lr=0.005)\n",
    "\n",
    "        return optimizer\n",
    "    \n",
    "    def _prepare_learning_scheduler(self, optimizer):\n",
    "        # Reference: https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR        \n",
    "        exp_lr_scheduler: torch.optim.lr_scheduler.StepLR = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
    "\n",
    "        return exp_lr_scheduler\n",
    "\n",
    "    def start_training_stacked_autoencoder_model(self, dataset_loader_dictionary: dict[str, torch.utils.data.DataLoader], device_to_process: torch.device,  number_of_epoch: int = 25 ) -> AutoEncoder:\n",
    "\n",
    "        # Move the autoencoder to GPU\n",
    "        self.stacked_autoencoder.to(device_to_process)\n",
    "\n",
    "        # Define the adam optimizer on Encoder\n",
    "        optimizer = self._prepare_optimizer(self.stacked_autoencoder.parameters())\n",
    "\n",
    "        # Define the learning scheduler\n",
    "        scheduler = self._prepare_learning_scheduler(optimizer)            \n",
    "\n",
    "        trained_stacked_autoencoder_model = self.train_model(dataset_loader_dictionary, self.stacked_autoencoder, optimizer, scheduler, number_of_epoch)\n",
    "\n",
    "\n",
    "        return trained_stacked_autoencoder_model\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicating the steps to train SDA-based deep learning architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of using the Stacked Denoising Autoencoder is to determine the optimal features to predict the target variable (\"L7Protocol\").\n",
    "\n",
    "The L7Protocol is the protocol used on the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised Layer-wise Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackedAutoEncoder = StackedAutoEncoder(80, 40 , 20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train the Stacked AutoEncoder using only Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Epoch 0 / 24\n",
      "\n",
      "Current Epoch 1 / 24\n",
      "\n",
      "Current Epoch 2 / 24\n",
      "\n",
      "Current Epoch 3 / 24\n",
      "\n",
      "Current Epoch 4 / 24\n",
      "\n",
      "Current Epoch 5 / 24\n",
      "\n",
      "Current Epoch 6 / 24\n",
      "\n",
      "Current Epoch 7 / 24\n",
      "\n",
      "Current Epoch 8 / 24\n",
      "\n",
      "Current Epoch 9 / 24\n",
      "\n",
      "Current Epoch 10 / 24\n",
      "\n",
      "Current Epoch 11 / 24\n",
      "\n",
      "Current Epoch 12 / 24\n",
      "\n",
      "Current Epoch 13 / 24\n",
      "\n",
      "Current Epoch 14 / 24\n",
      "\n",
      "Current Epoch 15 / 24\n",
      "\n",
      "Current Epoch 16 / 24\n",
      "\n",
      "Current Epoch 17 / 24\n",
      "\n",
      "Current Epoch 18 / 24\n",
      "\n",
      "Current Epoch 19 / 24\n",
      "\n",
      "Current Epoch 20 / 24\n",
      "\n",
      "Current Epoch 21 / 24\n",
      "\n",
      "Current Epoch 22 / 24\n",
      "\n",
      "Current Epoch 23 / 24\n",
      "\n",
      "Current Epoch 24 / 24\n",
      "\n",
      "Training complete in 33 minutes 41 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_stacked_autoencoder = stackedAutoEncoder.start_training_stacked_autoencoder_model(dataset_loader_dictionary, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_stacked_autoencoder.state_dict(), STACKED_AUTOENCODER_MODEL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stage will use the parameters from the previous stage of training in the Stacked Auto Encoder model.\n",
    "\n",
    "Once the training on the Stacked Auto Encoder is completed using the Validation dataset, the Logistic Regression model will be used to further calibrate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedStageStackedAutoEncoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, first_layer_dimension: int, second_layer_dimension: int, third_layer_dimension: int, latent_space_dimension: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stacked_autoencoder = torch.nn.Sequential(\n",
    "            AutoEncoder(first_layer_dimension, second_layer_dimension, third_layer_dimension, latent_space_dimension),\n",
    "            AutoEncoder(first_layer_dimension, second_layer_dimension, third_layer_dimension, latent_space_dimension),\n",
    "            AutoEncoder(first_layer_dimension, second_layer_dimension, third_layer_dimension, latent_space_dimension),\n",
    "        )\n",
    "\n",
    "    \n",
    "    def retrieve_parameters_from_unsupervised_stage_model(self, file_name: str):\n",
    "        self.stacked_autoencoder.load_state_dict(torch.load(STACKED_AUTOENCODER_MODEL_FILE_PATH, weights_only=True))\n",
    "        \n",
    "        \n",
    "    def train_supervised_stacked_auto_encoder_model(self, dataset_loader_dictionary: dict[str, torch.utils.data.DataLoader], dataset_sizes: dict[str, int] , model, criterion, optimizer, scheduler, number_of_epoch: int = 25 ):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        with TemporaryDirectory() as tempdir:\n",
    "            best_model_params_path = os.path.join(tempdir, 'best_supervised_stacked_autoencoder_model_params.pt')\n",
    "\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            best_accuracy: float = 0.0\n",
    "            \n",
    "            for epoch in range(number_of_epoch):\n",
    "\n",
    "                print(f\"Epoch {epoch} / {number_of_epoch - 1}\")\n",
    "                print(\"-\" * 10)\n",
    "\n",
    "                for phase in ['validation']:\n",
    "\n",
    "                    if phase == 'validation':\n",
    "                        model.train()\n",
    "\n",
    "                    \n",
    "                    running_loss: float = 0.0\n",
    "                    running_corrects: int = 0\n",
    "\n",
    "                    for inputs, labels in dataset_loader_dictionary[phase]:\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        with torch.set_grad_enabled(phase == 'validation'):\n",
    "                            outputs = model(inputs)\n",
    "                            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "                            # based on the research paper Section 2.2\n",
    "                            loss = criterion.forward(input=inputs, target=outputs)\n",
    "\n",
    "                            if phase == 'validation':\n",
    "                                loss.backward()\n",
    "                                optimizer.step()\n",
    "\n",
    "                        running_loss += loss.item() * inputs.size(0)\n",
    "                        running_corrects += torch.sum(predictions == labels.data)\n",
    "\n",
    "                    if phase == 'validation':\n",
    "                        scheduler.step()\n",
    "\n",
    "                    \n",
    "                    epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                    epoch_accuracy = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                    print(f\"{phase} Loss: {epoch_loss: .4f} Accuracy: {epoch_accuracy: .4f}\")\n",
    "\n",
    "                    if phase == 'validation' and epoch_accuracy > best_accuracy:\n",
    "                        best_accuracy = epoch_accuracy\n",
    "                        torch.save(model.state_dict(), best_model_params_path)\n",
    "                    \n",
    "                print()\n",
    "\n",
    "            time_elapsed = time.time() - start_time\n",
    "\n",
    "            print(f\"Training complete in {time_elapsed // 60:.0f} minutes {time_elapsed % 60:.0f} seconds\")\n",
    "            print(f\"Best Validation Accuracy: {best_accuracy:4f}\")\n",
    "            print(\"\")\n",
    "\n",
    "            model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "    def _prepare_criterion(self):\n",
    "        criterion: torch.nn.CrossEntropyLoss = torch.nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "    \n",
    "    def _prepare_optimizer(self, autoencoder_parameters):\n",
    "        #stackedAutoEncoder.autoencoder_decoder.parameters()\n",
    "        optimizer: torch.optim.Adam = torch.optim.Adam(autoencoder_parameters, lr=0.005)\n",
    "\n",
    "        return optimizer\n",
    "    \n",
    "    def _prepare_learning_scheduler(self, optimizer):\n",
    "        # Reference: https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR        \n",
    "        exp_lr_scheduler: torch.optim.lr_scheduler.StepLR = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
    "\n",
    "        return exp_lr_scheduler\n",
    "\n",
    "    def start_training_stacked_autoencoder_model(self, dataset_loader_dictionary: dict[str, torch.utils.data.DataLoader], dataset_sizes: dict[str, int], device_to_process: torch.device,  number_of_epoch: int = 25 ) -> AutoEncoder:\n",
    "\n",
    "        # Move the autoencoder to GPU\n",
    "        self.stacked_autoencoder.to(device_to_process)\n",
    "\n",
    "        # Define Criterion \n",
    "        criterion = self._prepare_criterion()\n",
    "\n",
    "        # Define the adam optimizer on Encoder\n",
    "        optimizer = self._prepare_optimizer(self.stacked_autoencoder.parameters())\n",
    "\n",
    "        # Define the learning scheduler\n",
    "        scheduler = self._prepare_learning_scheduler(optimizer)            \n",
    "\n",
    "        trained_stacked_autoencoder_model = self.train_supervised_stacked_auto_encoder_model(dataset_loader_dictionary, dataset_sizes, model=self.stacked_autoencoder,criterion=criterion, optimizer=optimizer, scheduler=scheduler, number_of_epoch=number_of_epoch)\n",
    "\n",
    "\n",
    "        return trained_stacked_autoencoder_model\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the Supervised Tuning Stacked Auto Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_stage_stacked_auto_encoder_model = SupervisedStageStackedAutoEncoder(80, 40, 20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load parameters from previous model in Unsupervised Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_stage_stacked_auto_encoder_model.retrieve_parameters_from_unsupervised_stage_model(STACKED_AUTOENCODER_MODEL_FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train the Stacked Autoencoder at Supervised Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 24\n",
      "----------\n",
      "validation Loss: -307076396038.4272 Accuracy:  0.0000\n",
      "\n",
      "Epoch 1 / 24\n",
      "----------\n",
      "validation Loss: -3160592499610.3428 Accuracy:  0.0000\n",
      "\n",
      "Epoch 2 / 24\n",
      "----------\n",
      "validation Loss: -11345278693320.3711 Accuracy:  0.0000\n",
      "\n",
      "Epoch 3 / 24\n",
      "----------\n",
      "validation Loss: -27418308341207.9883 Accuracy:  0.0000\n",
      "\n",
      "Epoch 4 / 24\n",
      "----------\n",
      "validation Loss: -53880082127673.7266 Accuracy:  0.0000\n",
      "\n",
      "Epoch 5 / 24\n",
      "----------\n",
      "validation Loss: -93222402602054.1094 Accuracy:  0.0000\n",
      "\n",
      "Epoch 6 / 24\n",
      "----------\n",
      "validation Loss: -147877445304823.1562 Accuracy:  0.0000\n",
      "\n",
      "Epoch 7 / 24\n",
      "----------\n",
      "validation Loss: -184494819426407.5000 Accuracy:  0.0000\n",
      "\n",
      "Epoch 8 / 24\n",
      "----------\n",
      "validation Loss: -191570838932076.0000 Accuracy:  0.0000\n",
      "\n",
      "Epoch 9 / 24\n",
      "----------\n",
      "validation Loss: -198821444409270.1562 Accuracy:  0.0000\n",
      "\n",
      "Epoch 10 / 24\n",
      "----------\n",
      "validation Loss: -206252720786116.0625 Accuracy:  0.0000\n",
      "\n",
      "Epoch 11 / 24\n",
      "----------\n",
      "validation Loss: -213866888550233.8750 Accuracy:  0.0000\n",
      "\n",
      "Epoch 12 / 24\n",
      "----------\n",
      "validation Loss: -221666168691580.8125 Accuracy:  0.0000\n",
      "\n",
      "Epoch 13 / 24\n",
      "----------\n",
      "validation Loss: -229652793393726.1562 Accuracy:  0.0000\n",
      "\n",
      "Epoch 14 / 24\n",
      "----------\n",
      "validation Loss: -234221208978587.6875 Accuracy:  0.0000\n",
      "\n",
      "Epoch 15 / 24\n",
      "----------\n",
      "validation Loss: -235246122411305.3438 Accuracy:  0.0000\n",
      "\n",
      "Epoch 16 / 24\n",
      "----------\n",
      "validation Loss: -236274021314950.5312 Accuracy:  0.0000\n",
      "\n",
      "Epoch 17 / 24\n",
      "----------\n",
      "validation Loss: -237304910098795.4688 Accuracy:  0.0000\n",
      "\n",
      "Epoch 18 / 24\n",
      "----------\n",
      "validation Loss: -238338802715882.0312 Accuracy:  0.0000\n",
      "\n",
      "Epoch 19 / 24\n",
      "----------\n",
      "validation Loss: -239375701528075.7812 Accuracy:  0.0000\n",
      "\n",
      "Epoch 20 / 24\n",
      "----------\n",
      "validation Loss: -240415586156515.6562 Accuracy:  0.0000\n",
      "\n",
      "Epoch 21 / 24\n",
      "----------\n",
      "validation Loss: -240936619608457.6875 Accuracy:  0.0000\n",
      "\n",
      "Epoch 22 / 24\n",
      "----------\n",
      "validation Loss: -240936619608457.6875 Accuracy:  0.0000\n",
      "\n",
      "Epoch 23 / 24\n",
      "----------\n",
      "validation Loss: -240936619608457.6875 Accuracy:  0.0000\n",
      "\n",
      "Epoch 24 / 24\n",
      "----------\n",
      "validation Loss: -240936619608457.6875 Accuracy:  0.0000\n",
      "\n",
      "Training complete in 42 minutes 56 seconds\n",
      "Best Validation Accuracy: 0.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_supervised_stage_stacked_auto_encoder_model = supervised_stage_stacked_auto_encoder_model.start_training_stacked_autoencoder_model(dataset_loader_dictionary, dataset_sizes,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the autoencoder model in this stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_supervised_stage_stacked_auto_encoder_model.state_dict(), SUPERVISED_STACKED_AUTOENCODER_MODEL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving the features from the Stacked Auto Encoder using Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the features that matters using autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTestSetStackedAutoEncoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, first_layer_dimension: int, second_layer_dimension: int, third_layer_dimension: int, latent_space_dimension: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stacked_autoencoder = torch.nn.Sequential(\n",
    "            AutoEncoder(first_layer_dimension, second_layer_dimension, third_layer_dimension, latent_space_dimension),\n",
    "            AutoEncoder(first_layer_dimension, second_layer_dimension, third_layer_dimension, latent_space_dimension),\n",
    "            AutoEncoder(first_layer_dimension, second_layer_dimension, third_layer_dimension, latent_space_dimension),\n",
    "        )\n",
    "\n",
    "    \n",
    "    def retrieve_parameters_from_supervised_stage_model(self, file_name: str):\n",
    "        self.stacked_autoencoder.load_state_dict(torch.load(SUPERVISED_STACKED_AUTOENCODER_MODEL_FILE_PATH, weights_only=True))\n",
    "        \n",
    "    def train_supervised_stacked_auto_encoder_model(self, dataset_loader_dictionary: dict[str, torch.utils.data.DataLoader], dataset_sizes: dict[str, int] , model, criterion, optimizer, scheduler, number_of_epoch: int = 25 ):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        with TemporaryDirectory() as tempdir:\n",
    "            best_model_params_path = os.path.join(tempdir, 'best_test_stacked_autoencoder_model_params.pt')\n",
    "\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            best_accuracy: float = 0.0\n",
    "            \n",
    "            for epoch in range(number_of_epoch):\n",
    "\n",
    "                print(f\"Epoch {epoch} / {number_of_epoch - 1}\")\n",
    "                print(\"-\" * 10)\n",
    "\n",
    "                for phase in ['test']:\n",
    "\n",
    "                    if phase == 'test':\n",
    "                        model.eval()\n",
    "\n",
    "                    \n",
    "                    running_loss: float = 0.0\n",
    "                    running_corrects: int = 0\n",
    "\n",
    "                    for inputs, labels in dataset_loader_dictionary[phase]:\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        with torch.set_grad_enabled(False):\n",
    "                            outputs = model(inputs)\n",
    "                            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "                            # based on the research paper Section 2.2\n",
    "                            loss = criterion.forward(input=inputs, target=outputs)\n",
    "\n",
    "                        running_loss += loss.item() * inputs.size(0)\n",
    "                        running_corrects += torch.sum(predictions == labels.data)\n",
    "                    \n",
    "                    epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                    epoch_accuracy = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                    print(f\"{phase} Loss: {epoch_loss: .4f} Accuracy: {epoch_accuracy: .4f}\")\n",
    "\n",
    "                    if phase == 'validation' and epoch_accuracy > best_accuracy:\n",
    "                        best_accuracy = epoch_accuracy\n",
    "                        torch.save(model.state_dict(), best_model_params_path)\n",
    "                    \n",
    "                print()\n",
    "\n",
    "            time_elapsed = time.time() - start_time\n",
    "\n",
    "            print(f\"Training complete in {time_elapsed // 60:.0f} minutes {time_elapsed % 60:.0f} seconds\")\n",
    "            print(f\"Best Test Accuracy: {best_accuracy:4f}\")\n",
    "            print(\"\")\n",
    "\n",
    "            model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "    def _prepare_criterion(self):\n",
    "        criterion: torch.nn.CrossEntropyLoss = torch.nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "    \n",
    "    def _prepare_optimizer(self, autoencoder_parameters):\n",
    "        #stackedAutoEncoder.autoencoder_decoder.parameters()\n",
    "        optimizer: torch.optim.Adam = torch.optim.Adam(autoencoder_parameters, lr=0.005)\n",
    "\n",
    "        return optimizer\n",
    "    \n",
    "    def _prepare_learning_scheduler(self, optimizer):\n",
    "        # Reference: https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR        \n",
    "        exp_lr_scheduler: torch.optim.lr_scheduler.StepLR = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
    "\n",
    "        return exp_lr_scheduler\n",
    "\n",
    "    def start_training_stacked_autoencoder_model(self, dataset_loader_dictionary: dict[str, torch.utils.data.DataLoader], dataset_sizes: dict[str, int], device_to_process: torch.device,  number_of_epoch: int = 25 ) -> AutoEncoder:\n",
    "\n",
    "        # Move the autoencoder to GPU\n",
    "        self.stacked_autoencoder.to(device_to_process)\n",
    "\n",
    "        # Define Criterion \n",
    "        criterion = self._prepare_criterion()\n",
    "\n",
    "        # Define the adam optimizer on Encoder\n",
    "        optimizer = self._prepare_optimizer(self.stacked_autoencoder.parameters())\n",
    "\n",
    "        # Define the learning scheduler\n",
    "        scheduler = self._prepare_learning_scheduler(optimizer)            \n",
    "\n",
    "        trained_stacked_autoencoder_model = self.train_supervised_stacked_auto_encoder_model(dataset_loader_dictionary, dataset_sizes, model=self.stacked_autoencoder,criterion=criterion, optimizer=optimizer, scheduler=scheduler, number_of_epoch=number_of_epoch)\n",
    "\n",
    "\n",
    "        return trained_stacked_autoencoder_model\n",
    "    \n",
    "    def retrieve_stacked_autoencoder(self):\n",
    "        return self.stacked_autoencoder\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_test_set_stacked_auto_encoder =  ClassificationTestSetStackedAutoEncoder(80, 40, 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_test_set_stacked_auto_encoder.retrieve_parameters_from_supervised_stage_model(SUPERVISED_STACKED_AUTOENCODER_MODEL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 1 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 2 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 3 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 4 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 5 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 6 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 7 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 8 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 9 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 10 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 11 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 12 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 13 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 14 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 15 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 16 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 17 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 18 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 19 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 20 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 21 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 22 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 23 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Epoch 24 / 24\n",
      "----------\n",
      "test Loss: -9.8632 Accuracy:  0.0000\n",
      "\n",
      "Training complete in 11 minutes 31 seconds\n",
      "Best Test Accuracy: 0.000000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AutoEncoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=40, bias=True)\n",
       "      (1): Linear(in_features=40, out_features=20, bias=True)\n",
       "      (2): Linear(in_features=20, out_features=10, bias=True)\n",
       "      (3): Sigmoid()\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (0): Sigmoid()\n",
       "      (1): Linear(in_features=10, out_features=20, bias=True)\n",
       "      (2): Linear(in_features=20, out_features=40, bias=True)\n",
       "      (3): Linear(in_features=40, out_features=80, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): AutoEncoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=40, bias=True)\n",
       "      (1): Linear(in_features=40, out_features=20, bias=True)\n",
       "      (2): Linear(in_features=20, out_features=10, bias=True)\n",
       "      (3): Sigmoid()\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (0): Sigmoid()\n",
       "      (1): Linear(in_features=10, out_features=20, bias=True)\n",
       "      (2): Linear(in_features=20, out_features=40, bias=True)\n",
       "      (3): Linear(in_features=40, out_features=80, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (2): AutoEncoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=40, bias=True)\n",
       "      (1): Linear(in_features=40, out_features=20, bias=True)\n",
       "      (2): Linear(in_features=20, out_features=10, bias=True)\n",
       "      (3): Sigmoid()\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (0): Sigmoid()\n",
       "      (1): Linear(in_features=10, out_features=20, bias=True)\n",
       "      (2): Linear(in_features=20, out_features=40, bias=True)\n",
       "      (3): Linear(in_features=40, out_features=80, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_test_set_stacked_auto_encoder.start_training_stacked_autoencoder_model(dataset_loader_dictionary, dataset_sizes,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = classification_test_set_stacked_auto_encoder.retrieve_stacked_autoencoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model.state_dict(), CLASSIFICATION_TEST_STACKED_AUTOENCODER_MODEL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post Processing to retrieve the reduce dimension features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_dimension: int = 80\n",
    "second_layer_dimension: int = 40\n",
    "third_layer_dimension: int = 20\n",
    "latent_space_dimension: int = 10\n",
    "\n",
    "stacked_autoencoder = torch.nn.Sequential(\n",
    "            AutoEncoder(first_layer_dimension, second_layer_dimension, third_layer_dimension, latent_space_dimension),\n",
    "            AutoEncoder(first_layer_dimension, second_layer_dimension, third_layer_dimension, latent_space_dimension),\n",
    "            AutoEncoder(first_layer_dimension, second_layer_dimension, third_layer_dimension, latent_space_dimension),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_autoencoder.load_state_dict(torch.load(CLASSIFICATION_TEST_STACKED_AUTOENCODER_MODEL_FILE_PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_normalized_tensor.to(device=device)\n",
    "\n",
    "sae_1_1 = stacked_autoencoder[0].encoder(test_dataset_normalized_tensor)\n",
    "sae_1_2 = stacked_autoencoder[0].decoder(sae_1_1)\n",
    "sae_2_1 = stacked_autoencoder[1].encoder(sae_1_2)\n",
    "sae_2_2 = stacked_autoencoder[1].decoder(sae_2_1)\n",
    "sae_3_1 = stacked_autoencoder[2].encoder(sae_2_2)\n",
    "sae_3_2 = stacked_autoencoder[2].decoder(sae_3_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_dataset = pandas.DataFrame(sae_3_1.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the dataset into training and testing sets.\n",
    "* Implement at least three different classification models (e.g., Decision Tree, Random Forest, SVM, etc.).\n",
    "* Train and fine-tune each model using appropriate techniques.\n",
    "* Discuss the choice of hyperparameters and the reasoning behind it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the dimension reduction technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "decision_tree_classifier = tree.DecisionTreeClassifier()\n",
    "\n",
    "decision_tree_classifier.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_from_x_test = decision_tree_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7235498839907193"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_classifier.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      1.00      0.92         6\n",
      "           5       0.73      0.65      0.68       353\n",
      "           7       0.82      0.82      0.82    136949\n",
      "           9       1.00      1.00      1.00        28\n",
      "          11       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         3\n",
      "          36       0.35      0.38      0.36        16\n",
      "          37       0.60      1.00      0.75         3\n",
      "          40       0.89      0.90      0.90      1719\n",
      "          48       0.00      0.00      0.00         1\n",
      "          51       1.00      0.33      0.50         3\n",
      "          60       0.40      0.37      0.38       100\n",
      "          64       0.23      0.28      0.25       170\n",
      "          67       0.57      1.00      0.73         8\n",
      "          68       0.46      0.47      0.46      2915\n",
      "          69       0.00      0.00      0.00         3\n",
      "          70       0.33      0.36      0.35      4162\n",
      "          81       1.00      1.00      1.00       334\n",
      "          85       0.00      0.00      0.00         1\n",
      "          91       0.76      0.76      0.76     80883\n",
      "          92       0.87      0.76      0.81        17\n",
      "         114       0.50      0.67      0.57         3\n",
      "         119       0.83      0.85      0.84      5753\n",
      "         120       0.34      0.35      0.35      3673\n",
      "         121       0.78      0.78      0.78      5052\n",
      "         122       0.23      0.25      0.24      8046\n",
      "         123       0.04      0.06      0.05       138\n",
      "         124       0.50      0.52      0.51     34117\n",
      "         125       0.51      0.51      0.51      6096\n",
      "         126       0.74      0.74      0.74    191682\n",
      "         130       0.71      0.71      0.71     63713\n",
      "         131       0.74      0.73      0.74    124860\n",
      "         132       0.00      0.00      0.00         3\n",
      "         133       0.27      0.27      0.27       324\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       0.38      0.46      0.41        13\n",
      "         139       0.67      0.44      0.53         9\n",
      "         140       0.56      0.59      0.57      1485\n",
      "         142       0.38      0.42      0.40       904\n",
      "         143       0.30      0.31      0.30       239\n",
      "         145       0.28      0.34      0.31       236\n",
      "         146       0.00      0.00      0.00         2\n",
      "         147       0.83      0.82      0.83      6988\n",
      "         148       0.78      0.77      0.78       121\n",
      "         150       0.00      0.00      0.00         1\n",
      "         153       0.10      0.20      0.13         5\n",
      "         156       0.32      0.34      0.33       244\n",
      "         158       0.20      0.20      0.20         5\n",
      "         159       0.00      0.00      0.00         2\n",
      "         162       0.00      0.00      0.00         3\n",
      "         163       0.11      0.15      0.13        46\n",
      "         164       0.00      0.00      0.00         3\n",
      "         167       0.00      0.00      0.00         3\n",
      "         169       0.48      0.55      0.51        40\n",
      "         170       0.20      0.50      0.29         2\n",
      "         174       0.00      0.00      0.00         1\n",
      "         175       0.06      0.08      0.07        50\n",
      "         176       0.29      0.31      0.30       398\n",
      "         178       0.64      0.65      0.65     17311\n",
      "         179       0.11      0.13      0.12       230\n",
      "         180       0.00      0.00      0.00         2\n",
      "         185       0.00      0.00      0.00         2\n",
      "         191       0.25      0.20      0.22        10\n",
      "         195       0.33      0.12      0.18         8\n",
      "         200       0.00      0.00      0.00         1\n",
      "         201       1.00      0.50      0.67         2\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.29      0.33      0.31       144\n",
      "         210       0.00      0.00      0.00         8\n",
      "         211       0.60      0.63      0.62       416\n",
      "         212       0.54      0.56      0.55     10875\n",
      "         213       0.00      0.00      0.00         0\n",
      "         219       0.73      0.76      0.74      1146\n",
      "         220       0.59      0.60      0.59      2928\n",
      "         221       0.34      0.34      0.34       385\n",
      "         222       0.32      0.43      0.36        56\n",
      "\n",
      "    accuracy                           0.72    715460\n",
      "   macro avg       0.38      0.38      0.37    715460\n",
      "weighted avg       0.73      0.72      0.72    715460\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/vscode/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/vscode/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/vscode/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/vscode/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/vscode/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test, y_predict_from_x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: Produce two types of model evaluation using test dataset and validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagged Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluate the models using appropriate classification metrics (accuracy, precision, recall, F1-score, etc.).\n",
    "* Visualize the model performance using ROC curves and confusion matrices.\n",
    "* Compare the models and justify your choice of the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
